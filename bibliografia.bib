% capitulo 2 - seccion 1
@article{Chen2023,
	abstract = {The emergence of large language models and conversational front-ends such as ChatGPT is revolutionizing many software engineering activities. The extent to which such technologies can help with requirements engineering activities, especially the ones surrounding modeling, however, remains to be seen. This paper reports on early experimental results on the potential use of GPT-4 in the latter context, with a focus on the development of goal-oriented models. We first explore GPT-4's current knowledge and mastering of a specific modeling language, namely the Goal-oriented Requirement Language (GRL). We then use four combinations of prompts - with and without a proposed textual syntax, and with and without contextual domain knowledge - to guide the creation of GRL models for two case studies. The first case study focuses on a well-documented topic in the goal modeling community (Kids Help Phone), whereas the second one explores a context for which, to our knowledge, no public goal models currently exist (Social Housing). We explore the interactive construction of a goal model through specific follow-up prompts aimed to fix model issues and expand on the model content. Our results suggest that GPT-4 preserves considerable knowledge on goal modeling, and although many elements generated by GPT-4 are generic, reflecting what is already in the prompt, or even incorrect, there is value in getting exposed to the generated concepts, many of which being non-obvious to stakeholders outside the domain. Furthermore, aggregating results from multiple runs yields a far better outcome than from any individual run.},
	author = {Boqi Chen and Kua Chen and Shabnam Hassani and Yujing Yang and Daniel Amyot and Lysanne Lessard and Gunter Mussbacher and Mehrdad Sabetzadeh and Daniel Varro},
	doi = {10.1109/REW57809.2023.00052},
	isbn = {9798350326918},
	journal = {Proceedings - 31st IEEE International Requirements Engineering Conference Workshops, REW 2023},
	keywords = {ChatGPT,GPT-4,GRL,Goal Modeling,Goal-oriented Requirement Language,Large Language Models},
	pages = {262-271},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {On the Use of {GPT-4} for {Creating Goal Models}: {An Exploratory Study}},
	year = {2023},
}
@article{Khan2022,
	abstract = {Source code documentation is an important artifact for efficient software development. Code documentation could greatly benefit from automation since manual documentation is often labouring, resource and time-intensive. In this paper, we employed Codex for automatic code documentation creation. Codex is a GPT-3 based model pre-trained on both natural and programming languages. We find that Codex outperforms existing techniques even with basic settings like one-shot learning (i.e., providing only one example for training). Codex achieves an overall BLEU score of 20.6 for six different programming languages (11.2% improvement over earlier state-of-the-art techniques). Thus, Codex shows promise and warrants in-depth future studies for automatic code documentation generation to support diverse development tasks.},
	author = {Junaed Younus Khan and Gias Uddin},
	doi = {10.1145/3551349.3559548},
	isbn = {9781450396240},
	journal = {ACM International Conference Proceeding Series},
	keywords = {GPT-3,Machine Learning.,code documentation},
	publisher = {Association for Computing Machinery},
	title = {{Automatic} {Code} {Documentation} {Generation} {Using} {GPT}-3},
	url = {https://dl.acm.org/doi/10.1145/3551349.3559548},
	year = {2022},
}
@article{Balse2023,
	abstract = {Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course. We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.},
	author = {Rishabh Balse and Bharath Valaboju and Shreya Singhal and Jayakrishnan Madathil Warriem and Prajish Prasad},
	doi = {10.1145/3587102.3588852},
	isbn = {9798400701382},
	issn = {1942647X},
	journal = {Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE},
	keywords = {GPT-3,evaluation,feedback,large language models (LLM),python programming},
	pages = {292-298},
	publisher = {Association for Computing Machinery},
	title = {{Investigating} the {Potential} of {GPT}-3 in {Providing} {Feedback} for {Programming} {Assessments}},
	volume = {1},
	url = {https://dl.acm.org/doi/10.1145/3587102.3588852},
	year = {2023},
}
@article{WuLing2023,
	abstract = {Knowledge graphs have revolutionized the organization and retrieval of real-world knowledge, prompting interest in automatic NLP-based approaches for extracting medical knowledge from texts. Howeve...},
	author = {WuLing-I and SuYuxin and LiGuoqiang},
	doi = {10.1145/3657305},
	issn = {2158-656X},
	journal = {ACM Transactions on Management Information Systems},
	keywords = {ChatGPT,Medical knowledge graph,Named entity recognition,Nature language processing,Relation extraction},
	publisher = {ACMPUB27New York, NY},
	title = {{Zero}-{Shot} {Construction} of {Chinese} {Medical} {Knowledge} {Graph} with {GPT}-3.5-turbo and {GPT}-4},
	url = {https://dl.acm.org/doi/10.1145/3657305},
	year = {2023},
}
@article{Lucke2024,
	abstract = {Starting in November 2022 with the free provision of ChatGPT, large language models (LLM) are now publicly available. This has significantly increased the number of publications which scopes potent...},
	author = {Jörn Von Lucke and Sander Frank},
	doi = {10.1145/3665333},
	issn = {2691-199X},
	journal = {Digital Government: Research and Practice},
	keywords = {ChatGPT,GPT 3.5,GPT-4,large language model,parliament},
	publisher = {ACMPUB27New York, NY},
	title = {{A} few {Thoughts} on the {Use} of {{ChatGPT}}, {GPT 3.5}, {GPT-4} and {LLMs} in {Parliaments}: {Reflecting} on the results of experimenting with {LLMs} in the parliamentarian context},
	url = {https://dl.acm.org/doi/10.1145/3665333},
	year = {2024},
	pages = {1-12},
	volume = {5}
}
@article{Sagodi2024,
	abstract = {Discovering and mitigating software vulnerabilities is a challenging task. These vulnerabilities are often caused by simple, otherwise (and in other contexts) harmless code snippets (e.g., unchecked path traversal). Large Language Models (LLMs) promise to revolutionize not just human-machine interactions but various software engineering tasks as well, including the automatic repair of vulnerabilities. However, currently, it is hard to assess the performance, robustness, and reliability of these models as most of their evaluation has been done on small, synthetic examples. In our work, we systematically evaluate the automatic vulnerability fixing capabilities of GPT-4, a popular LLM, using a database of real-world Java vulnerabilities, Vul4J. We expect the model to provide fixes for vulnerable methods, which we evaluate manually and based on unit test results included in the Vul4J database. GPT-4 provided perfect fixes consistently for at least 12 out of the total 46 examined vulnerabilities, which could be applied as is. In an additional 5 cases, the provided tex-tual instructions would help to fix the vulnerabilities in a practical scenario (despite the provided code being incorrect). Our findings, similar to others, also show that prompting has a significant effect. CCS CONCEPTS • Software and its engineering → Software maintenance tools.},
	author = {Zoltán Ságodi and Gábor Antal and Bence Bogenfürst and Martin Isztin and Péter Hegedűs and Rudolf Ferenc},
	doi = {10.1145/3661167.3661207},
	isbn = {9798400717017},
	keywords = {Automated program repair,GPT,Machine learning,Vulnerability fixing},
	pages = {252-261},
	publisher = {Association for Computing Machinery (ACM)},
	title = {Reality Check: Assessing {GPT-4} in {Fixing Real-World Software Vulnerabilities}},
	url = {https://dl.acm.org/doi/10.1145/3661167.3661207},
	year = {2024},
}
@article{Lim2024,
	abstract = {This research introduces a strategy that leverages GPT-4 Turbo, an advanced AI language model, to minimize human errors encountered while complying with the OWASP Top Ten security guidelines in software development. The framework combines the AI's capabilities in text comprehension and generation with developers' expertise to reduce errors. It delves into integrating GPT-4 Turbo across the Software Development Life Cycle (SDLC), proposing a model that enhances both software security and reliability. This framework addresses and adapts to the regularly updated OWASP vulnerabilities, contributing to reduced human errors and improved security measures. Furthermore, it benefits in streamlining processes and accelerating decision-making within business strategy contexts, demonstrating the multifaceted advantages of integrating sophisticated AI solutions in software development and management practices.},
	author = {Hansoo Lim and Jan Erik Meidell and Hyun-Jung Kim},
	issn = {2508-8270},
	issue = {3},
	journal = {차세대융합기술학회논문지},
	keywords = {Artificial intelligence,GPT-4 Turbo,Human errors,OWASP Top Ten Security Guidelines,OWASP 상위 10개 보안 지침,Software Development Lifecycle (SDLC),소프트웨어 개발 생명주기(SDLC),인공지능,인적 오류},
	pages = {864-872},
	title = {{Advancing} {Software} {Security} and {Reliability} {Through} {GPT}-4 {Turbo} in the {Software} {Development} {Life} {Cycle}},
	volume = {8},
	url = {https://www.earticle.net/Article/A444106},
	year = {2024},
}
@article{Cámara2023,
	abstract = {Most experts agree that large language models (LLMs), such as those used by Copilot and ChatGPT, are expected to revolutionize the way in which software is developed. Many papers are currently devoted to analyzing the potential advantages and limitations of these generative AI models for writing code. However, the analysis of the current state of LLMs with respect to software modeling has received little attention. In this paper, we investigate the current capabilities of ChatGPT to perform modeling tasks and to assist modelers, while also trying to identify its main shortcomings. Our findings show that, in contrast to code generation, the performance of the current version of ChatGPT for software modeling is limited, with various syntactic and semantic deficiencies, lack of consistency in responses and scalability issues. We also outline our views on how we perceive the role that LLMs can play in the software modeling discipline in the short term, and how the modeling community can help to improve the current capabilities of ChatGPT and the coming LLMs for software modeling.},
	author = {Javier Cámara and Javier Troya and Lola Burgueño and Antonio Vallecillo},
	doi = {10.1007/S10270-023-01105-5/FIGURES/5},
	issn = {16191374},
	issue = {3},
	journal = {Software and Systems Modeling},
	keywords = {ChatGPT,Large language models,Modeling languages,Software models,UML},
	pages = {781-793},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	title = {{On} the assessment of generative {AI} in modeling tasks: an experience report with {ChatGPT} and {UML}}, 
	volume = {22},
	url = {https://link.springer.com/article/10.1007/s10270-023-01105-5},
	year = {2023},
}
@article{Bajaj2024,
	abstract = {Microservice architecture (MSA) has become a new style to modernize monolithic systems. MSA comprises small, independent, and autonomous services that communicate using lightweight network protocols. Recently few studies have proposed microservice identification techniques to embrace the designing of microservices. However, majority of the existing approaches are applicable to brownfield applications where monolithic application already exists. In this paper, we introduce a novel Greenfield Transformer-based Microservice identification approach—GTMicro to identify the bounded context as microservices for greenfield applications. GTMicro makes use of Bidirectional Encoder Representations from Transformers (BERT) which is a deep Learning model. BERT is used to compute the semantic textual similarity between use cases of the application and group them semantically. We validated GTMicro on two sample benchmark monolithic Java applications and migrated them toward microservices-based architecture. We mapped GTMicro to the state-of-the-art software quality assessment metrics and have presented the gains achieved through our results.},
	author = {Deepali Bajaj and Urmil Bharti and Isha Gupta and Priya Gupta and Asha Yadav},
	doi = {10.1007/S41870-024-01766-5/TABLES/5},
	issn = {25112112},
	issue = {5},
	journal = {International Journal of Information Technology},
	keywords = {BERT,GPT-3,Greenfield applications,Microservice identification,Semantic textual similarity (STS),TF-IDF,Transformer models},
	pages = {2751-2761},
	publisher = {Springer Science and Business Media B.V.},
	title = {{GTMicro}—microservice identification approach based on deep {NLP} transformer model for greenfield developments},
	volume = {16},
	url = {https://link.springer.com/article/10.1007/s41870-024-01766-5},
	year = {2024},
}
@article{Muralitharan2024,
	abstract = {In this modern digital era, the increasing volume of textual data and the widespread adoption of natural language processing (NLP) techniques have presented a critical challenge in safeguarding sensitive privacy information. As a result, there is a pressing demand to design robust and accurate NLP-based techniques to perform efficient sensitive information detection in textual data. This research paper focuses on the detection and classification of sensitive privacy information in textual documents using NLP by proposing a novel algorithm named Privacy BERT-LSTM. The proposed Privacy BERT-LSTM algorithm employs BERT for obtaining contextual embeddings and LSTM for sequential information processing, facilitating efficient sensitive information detection in textual documents. The BERT with its bidirectional characteristics captures the nuances and meaning of the textual documents, while the LSTM derives the long-range dependencies in the textual data. Moreover, the proposed Privacy BERT-LSTM algorithm with its attention mechanism highlights the important regions of the textual documents, contributing to efficient sensitive information detection. The comprehensive performance evaluation is conducted by employing the SMS Spam Collection dataset in terms of standard performance metrics and comparing it with different state-of-the-art techniques, namely, CASSED, PRIVAFRAME, CNN-LSTM, Conv-FFD, GCSA, TSIIP, and, C-PIIM. The experimental outcomes clearly illustrate that the Privacy BERT-LSTM algorithm demonstrates superior performance in identifying various types of sensitive information by achieving an accuracy of 92.50%, F1-score of 85.02%, and Precision of 89.36%. The proposed algorithm outperforms existing baseline models, providing valuable advancements in sensitive information detection using NLP. Therefore, this research contributes to the advancement of privacy protection in NLP applications and opens avenues for future investigations in the domain of sensitive information detection. Additionally, the proposed algorithm provides valuable insights for researchers and practitioners working on privacy-sensitive NLP tasks.},
	author = {Janani Muralitharan and Chandrasekar Arumugam},
	doi = {10.1007/S00521-024-09707-W/TABLES/6},
	issn = {14333058},
	journal = {Neural Computing and Applications},
	keywords = {BERT,Class imbalance,LSTM,NLP,Sensitive information detection,Textual documents},
	pages = {1-16},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	title = {{Privacy} {BERT}-{LSTM}: a novel {NLP} algorithm for sensitive information detection in textual documents},
	url = {https://link.springer.com/article/10.1007/s00521-024-09707-w},
	year = {2024},
}
@misc{Elon2024,
	author = {Sam Altman and Greg Brockman and Ilya Sutskever and John Schulman and Wojciech Zaremba and Elon Musk},
	journal = {https://platform.openai.com/},
	title = {{Models - OpenAI API}},
	url = {https://platform.openai.com/docs/models},
	howpublished = {\url{https://platform.openai.com/docs/models}},
	year = {2024},
}
@inproceedings{Gokcimen2023,
	abstract = {With the latest developments in artificial intelligence, language models have reached the level that can produce human-like responses. One of the most successful examples of these technologies is the GPT-3 language model developed by OpenAI. This study aims to investigate how similar human responses and artificial intelligence responses are, and which transformer model performs best. In the study, a series of questions were answered using different transformer-based models and compared with the answers given by humans. The highest performance was obtained with the roberta-base-openai-detector model. This study provides researchers with a different perspective to understand the difference between artificial intelligence technologies and human responses.},
	author = {Tunahan Gokcimen and Bihter Das},
	doi = {10.1109/IISEC59749.2023.10391042},
	isbn = {9798350318036},
	journal = {4th International Informatics and Software Engineering Conference - Symposium Program, IISEC 2023},
	keywords = {ChatGPT,Human-like responses,NLP,OpenAI,transformer-based models},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Analyzing} {Human} and {ChatGPT} {Responses}: {A} {Comparative} {Study} of {Transformer} {Models} in {Natural} {Language} {Processing}},
	year = {2023},
}
@article{Alto2023,
	abstract = {[First edition]. Generative AI models and AI language models are becoming increasingly popular due to their unparalleled capabilities. This book will provide you with insights into the inner workings of the LLMs and guide you through creating your own language models. You'll start with an introduction to the field of generative AI, helping you understand how these models are trained to generate new data. Next, you'll explore use cases where ChatGPT can boost productivity and enhance creativity. You'll learn how to get the best from your ChatGPT interactions by improving your prompt design and leveraging zero, one, and few-shots learning capabilities. The use cases are divided into clusters of marketers, researchers, and developers, which will help you apply what you learn in this book to your own challenges faster. You'll also discover enterprise-level scenarios that leverage OpenAI models' APIs available on Azure infrastructure; both generative models like GPT-3 and embedding models like Ada. For each scenario, you'll find an end-to-end implementation with Python, using Streamlit as the frontend and the LangChain SDK to facilitate models' integration into your applications. By the end of this book, you'll be well equipped to use the generative AI field and start using ChatGPT and OpenAI models' APIs in your own projects. Cover -- Title Page -- Copyright and credits -- Contributors -- Table of Contents -- Preface -- Part 1: Fundamentals of Generative AI and GPT Models -- Chapter 1: Introduction to Generative AI -- Introducing generative AI -- Domains of generative AI -- Text generation -- Image generation -- Music generation -- Video generation -- The history and current status of research -- Summary -- References -- Chapter 2: OpenAI and ChatGPT -- Beyond the Market Hype -- Technical requirements -- What is OpenAI? -- An overview of OpenAI model families -- Road to ChatGPT: the math of the model behind it -- The structure of RNNs -- The main limitations of RNNs -- Overcoming limitations -- introducing transformers -- GPT-3 -- ChatGPT: the state of the art -- Summary -- References -- Part 2: ChatGPT in Action -- Chapter 3: Getting Familiar with ChatGPT -- Setting up a ChatGPT account -- Familiarizing yourself with the UI -- Organizing chats -- Summary -- References -- Chapter 4: Understanding Prompt Design -- What is a prompt and why is it important? -- Zero-, one-, and few-shot learning -- typical of transformers models -- Principles of well-defined prompts to obtain relevant and consistent results -- Avoiding the risk of hidden bias and taking into account ethical considerations in ChatGPT -- Summary -- References -- Chapter 5: Boosting Day-to-Day Productivity with ChatGPT -- Technical requirements -- ChatGPT as a daily assistant -- Generating text -- Improving writing skills and translation -- Quick information retrieval and competitive intelligence -- Summary -- Chapter 6: Developing the Future with ChatGPT -- Why ChatGPT for developers? -- Generating, optimizing, and debugging code -- Generating documentation and code explainability -- Understanding ML model interpretability -- Translation among different programming languages -- Summary. Chapter 7: Mastering Marketing with ChatGPT -- Technical requirements -- Marketers' need for ChatGPT -- New product development and the go-to-market strategy -- A/B testing for marketing comparison -- Boosting Search Engine Optimization (SEO) -- Sentiment analysis to improve quality and increase customer satisfaction -- Summary -- Chapter 8: Research Reinvented with ChatGPT -- Researchers' need for ChatGPT -- Brainstorming literature for your study -- Providing support for the design and framework of your experiment -- Generating and formatting a bibliography -- Generating a presentation of the study -- Summary -- References -- Part 3: OpenAI for Enterprises -- Chapter 9: OpenAI and ChatGPT for Enterprises -- Introducing Azure OpenAI -- Technical requirements -- OpenAI and Microsoft for enterprise-level AI -- introducing Azure OpenAI -- Microsoft AI background -- Azure OpenAI Service -- Exploring Playground -- Why introduce a public cloud? -- Understanding responsible AI -- Microsoft's journey toward responsible AI -- Azure OpenAI and responsible AI -- Summary -- References -- Chapter 10: Trending Use Cases for Enterprises -- Technical requirements -- How Azure OpenAI is being used in enterprises -- Contract analyzer and generator -- Identifying key clauses -- Analyzing language -- Flagging potential issues -- Providing contract templates -- Frontend with Streamlit -- Understanding call center analytics -- Parameter extraction -- Sentiment analysis -- Classification of customers' requests -- Implementing the frontend with Streamlit -- Exploring semantic search -- Document embedding using LangChain modules -- Creating a frontend for Streamlit -- Summary -- References -- Chapter 11: Epilogue and Final Thoughts -- Recap of what we have learned so far -- This is just the beginning -- The advent of multimodal large language models. Microsoft Bing and the Copilot system -- The impact of generative technologies on industries -- a disruptive force -- Unveiling concerns about Generative AI -- Elon Musk calls for stopping development -- ChatGPT was banned in Italy by the Italian "Garante della Privacy" -- Ethical implications of Generative AI and why we need Responsible AI -- What to expect in the near future -- Summary -- References -- Index -- Other Books You May Enjoy.},
	author = {Valentina Alto},
	isbn = {9781805122838},
	journal = {IEEE Transactions on Fuzzy Systems},
	pages = {286},
	title = {{Modern} generative {AI} with {ChatGPT} and {OpenAI} models : leverage the capabilities of {OpenAI}'s {LLM} for productivity and innovation with {GPT3} and {GPT4}},
	year = {2023},
}
@article{Arif2023,
	abstract = {Software requirements are the expectation of stakeholders which are identified and modeled by various requirements elicitation and modeling techniques like traditional methods, goal oriented methods, and unified modeling language (UML), etc. The identified software requirements are broadly classified into functional requirements (FRs) and non-functional requirements (NFRs). Based on our literature review, we found that most of the focus in the area of software engineering is on the analysis of FRs as compared to NFRs. For the successful development of any information system both FRs and NFRs should be considered equally during the elicitation and modeling process; and ignoring NFRs may lead to failure of software. Therefore, to address this issue, we developed a method for the analysis of both FRs and NFRs so that a successful software product can be developed by a software company. In the proposed method, FRs are modeled by UML use-case diagram, class-diagram, and activity diagram. The NFRs are analyzed using NFR-framework; and NFR propagation rules have been derived from the requirements of an information system. In this framework, fuzzy based approach has been used to analyze the contribution links of softgoal interdependency graph. The applicability of the proposed method is discussed by using FRs and NFRs of library information system.},
	author = {Mohd Arif and Chaudhary Wali Mohammad and Mohd Sadiq},
	doi = {10.1007/S41870-022-01112-7/TABLES/2},
	issn = {25112112},
	issue = {1},
	journal = {International Journal of Information Technology (Singapore)},
	keywords = {Functional requirements,Library information system,Non-functional requirements,Software requirements,UML},
	pages = {411-422},
	publisher = {Springer Science and Business Media B.V.},
	title = {{UML} and {NFR}-framework based method for the analysis of the requirements of an information system},
	volume = {15},
	url = {https://link.springer.com/article/10.1007/s41870-022-01112-7},
	year = {2023},
}
@article{Flavia2023,
	abstract = {Model-based engineering emerged as an approach to tackle the complexity of current system development. In particular, compositional strategies assume that systems can be built from reusable and loosely coupled units. However, it is still a challenge to ensure that desired properties hold for component integration. We present a component-based model for UML, including a metamodel, well-formedness conditions and formal semantics via translation into BRIC; the presentation of the semantics is given by a set of rules that cover all the metamodel elements and map them to their respective BRIC denotations. We use our previous work on BRIC as an underlying (and totally hidden) component development framework so that our approach benefits from all the formal infrastructure developed for BRIC using CSP. Component composition, specified via UML structural diagrams, ensures adherence to classical concurrent properties: our focus is on the preservation of deadlock freedom. Automated support is developed as a plug-in to the Astah modelling tool. Verification is carried out using FDR (a model checker for CSP); we address scalability using compositional reasoning (inherent to the approach) and behavioural patterns. The formal reasoning is transparent to the user: a distinguishing feature of our approach is its support for traceability. For instance, when FDR uncovers a deadlock, a sequence diagram is constructed from the deadlock trace and presented to the user at the modelling level. The overall approach is illustrated with a running example and two additional case studies.},
	author = {Flávia Falcão and Lucas Lima and Augusto Sampaio and Pedro Antonino},
	doi = {10.1007/S10270-023-01127-Z/TABLES/5},
	issn = {16191374},
	journal = {Software and Systems Modeling},
	keywords = {CSP,Component,Compositional verification,Deadlock analysis,UML},
	pages = {1-34},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	title = {{A} formal component model for {UML} based on {CSP} aiming at compositional verification},
	url = {https://link.springer.com/article/10.1007/s10270-023-01127-z},
	year = {2023},
}
@article{Zhu2023,
	abstract = {Understanding the rationale behind the predictions produced by machine learning models is a necessary prerequisite for human to build confidence and trust for the intelligent systems. To tackle the problem of interpretability faced by black-box models, a fuzzy local surrogate model is proposed in this study to articulate the rationale for predictions to enhance the interpretability of the results of machine learning models. Fuzzy rule-based model comes with high interpretability since it is composed of a collection of readable rules, and thus is suitable for prediction interpretation. The general scheme of fuzzy local surrogate model is composed of the following phases: i) select data points around the instance of interest, for which we wish to explain the prediction result produced by the predictive model; ii) generate predictions for these newly selected data and weight the selected data based on the distance from the instance of interest; and iii) a fuzzy rule-based model composed a collection of interpretable is constructed to approximate the weighted data and offer meaningful interpretation to the prediction result of the given instance. The proposed fuzzy model for explaining predictions is model-agnostic and could provide high estimation accuracy. The proposed methodology offers a significant original contribution to the interpretation of machine learning models. Experimental studies demonstrate the usefulness of the proposed fuzzy local surrogate model in providing local explanations.},
	author = {Xiubin Zhu and Dan Wang and Witold Pedrycz and Zhiwu Li},
	doi = {10.1109/TFUZZ.2022.3218426},
	issn = {19410034},
	issue = {6},
	journal = {IEEE Transactions on Fuzzy Systems},
	keywords = {Fuzzy rule-based model,interpretability,local surrogate model,machine learning,model-agnostic},
	pages = {2056-2064},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Fuzzy} {Rule}-{Based} {Local} {Surrogate} {Models} for {Black}-{Box} {Model} {Explanation}},
	volume = {31},
	year = {2023},
}
@article{Hanyu2023,
	abstract = {Generally, fuzzy models, especially rule-based models, are designed in a monolithic manner, meaning that all data are used en bloc to design the model. At the same time, there is a visible need to cope with the ever-increasing volumes of data (both in terms of the number of data and their dimensionality) as well as being faced with distributed data located at various locations. The objective of this article is to develop a concept and provide a design framework as well as assess its performance for constructing a collection of rule-based models on a basis of a randomly sampled repository of data and then realize their aggregation. More specifically, for the sampled data, the design of each model is carried out in a standard way as commonly encountered in the case of Takagi-Sugeno (TS) rule-based models and next augmented by gradient boosting. The aggregation is realized by optimizing a weighting scheme applied to the results of the individual models. Our intent is also to carefully demonstrate the performance offered by the mechanisms of machine learning applied in the setting of rule-based models, which is an original task completed before. A number of high-dimensional data are used in the experimental studies to complete a thorough assessment. A comparative performance analysis is reported with respect to the monolithically developed TS models.},
	author = {E. Hanyu and Ye Cui and Witold Pedrycz and Zhiwu Li},
	doi = {10.1109/TFUZZ.2022.3226250},
	issn = {19410034},
	issue = {7},
	journal = {IEEE Transactions on Fuzzy Systems},
	keywords = {Aggregation,curse of dimensionality,data dimensionality,distributed rule-based model,gradient boosting},
	pages = {2479-2486},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Design} of {Distributed} {Rule}-{Based} {Models} in the {Presence} of {Large} {Data}},
	volume = {31},
	year = {2023},
}

% capitulo 2 - seccion 2

@article{Hou2024,
	abstract = {GPT has demonstrated impressive capabilities in executing various natural language processing (NLP) and reasoning tasks, showcasing its potential for deductive coding in social annotations. This research explored the effectiveness of prompt engineering and fine-tuning approaches of GPT for deductive coding of context-dependent and context-independent dimensions. Coding context-dependent dimensions (i.e., Theorizing, Integration, Reflection) requires a contextualized understanding that connects the target comment with reading materials and previous comments, whereas coding context-independent dimensions (i.e., Appraisal, Questioning, Social, Curiosity, Surprise) relies more on the comment itself. Utilizing strategies such as prompt decomposition, multi-prompt learning, and a codebook-centered approach, we found that prompt engineering can achieve fair to substantial agreement with expert-labeled data across various coding dimensions. These results affirm GPT's potential for effective application in real-world coding tasks. Compared to context-independent coding, context-dependent dimensions had lower agreement with expert-labeled data. To enhance accuracy, GPT models were fine-tuned using 102 pieces of expert-labeled data, with an additional 102 cases used for validation. The fine-tuned models demonstrated substantial agreement with ground truth in context-independent dimensions and elevated the inter-rater reliability of context-dependent categories to moderate levels. This approach represents a promising path for significantly reducing human labor and time, especially with large unstructured datasets, without sacrificing the accuracy and reliability of deductive coding tasks in social annotation. The study marks a step toward optimizing and streamlining coding processes in social annotation. Our findings suggest the promise of using GPT to analyze qualitative data and provide detailed, immediate feedback for students to elicit deepening inquiries.},
	author = {Chenyu Hou and Gaoxia Zhu and Juan Zheng and Lishan Zhang and Xiaoshan Huang and Tianlong Zhong and Shan Li and Hanxiang Du and Chin Lee Ker},
	doi = {10.1145/3636555.3636910},
	isbn = {9798400716188},
	journal = {ACM International Conference Proceeding Series},
	keywords = {Context-Dependent,Fine-tuning,GPT,Prompt Engineering,Social Annotation,deductive coding},
	pages = {518-528},
	publisher = {Association for Computing Machinery},
	title = {{Prompt}-based and {Fine}-tuned {GPT} {Models} for {Context}-{Dependent} and -{Independent} {Deductive} {Coding} in {Social} {Annotation}},
	url = {https://dl.acm.org/doi/10.1145/3636555.3636910},
	year = {2024},
}

@article{JLi2024,
	abstract = {AI pair programmers, such as GitHub's Copilot, have shown great success in automatic code generation. However, such large language model-based code generation techniques face the risk of introducing security vulnerabilities to codebases. In this work, we explore the direction of fine-tuning large language models for generating more secure code. We use real-world vulnerability fixes as our fine-tuning dataset. We craft a code-generation scenario dataset (C/C++) for evaluating and comparing the pre-trained and fine-tuned models. Our experiments on GPT-J show that the fine-tuned GPT-J achieved 70.4% and 64.5% ratios of non-vulnerable code generation for C and C++, respectively, which has a 10% increase for C and a slight increase for C++ compared with the pre-trained large language model.},
	author = {Junjie Li and Aseem Sangalay and Cheng Cheng and Yuan Tian and Jinqiu Yang},
	doi = {10.1145/3650105.3652299},
	isbn = {9798400706097},
	keywords = {Artificial Intelligence (AI),Code Generation,Com-mon Weakness Enumerations (CWEs),Cybersecurity},
	pages = {86-90},
	publisher = {Association for Computing Machinery (ACM)},
	journal = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
	title = {Fine Tuning Large Language Model for Secure Code Generation},
	url = {https://dl.acm.org/doi/10.1145/3650105.3652299},
	year = {2024},
}

@article{JunyiLi2024,
	abstract = {Text Generation aims to produce plausible and readable text in human language from input data. The resurgence of deep learning has greatly advanced this field, in particular, with the help of neural generation models based on pre-trained language models (PLMs). Text generation based on PLMs is viewed as a promising approach in both academia and industry. In this article, we provide a survey on the utilization of PLMs in text generation. We begin with introducing two key aspects of applying PLMs to text generation: (1) how to design an effective PLM to serve as the generation model; and (2) how to effectively optimize PLMs given the reference text and to ensure that the generated texts satisfy special text properties. Then, we show the major challenges that have arisen in these aspects, as well as possible solutions for them. We also include a summary of various useful resources and typical text generation applications based on PLMs. Finally, we highlight the future research directions which will further improve these PLMs for text generation. This comprehensive survey is intended to help researchers interested in text generation problems to learn the core concepts, the main techniques and the latest developments in this area based on PLMs.},
	author = {Junyi Li and Tianyi Tang and Wayne Xin Zhao and Jian Yun Nie and Ji Rong Wen},
	doi = {10.1145/3649449/ASSET/C6BA28DA-65BE-4C43-AB54-7E6B88C59F8F/ASSETS/GRAPHIC/CSUR-2022-0328-F01.JPG},
	issn = {15577341},
	issue = {9},
	journal = {ACM Computing Surveys},
	keywords = {Pre-trained language models, natural language processing},
	pages = {230},
	publisher = {Association for Computing Machinery},
	title = {{Pre}-{Trained} {Language} {Models} for {Text} {Generation}: {A} {Survey}},
	volume = {56},
	url = {https://dl.acm.org/doi/10.1145/3649449},
	year = {2024},
}

@article{Liesenfeld2023,
	abstract = {Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.},
	author = {Andreas Liesenfeld and Andreas Liesenfeld@ru Nl and Alianda Lopez and Ada Lopez@ru Nl and Mark Dingemanse},
	doi = {10.1145/3571884.3604316},
	isbn = {9798400700149},
	journal = {Proceedings of the 5th International Conference on Conversational User Interfaces, CUI 2023},
	keywords = {RLHF,chatGPT,large language models,open source,survey},
	publisher = {Association for Computing Machinery, Inc},
	title = {{Opening} up {ChatGPT}: {Tracking} openness, transparency, and accountability in instruction-tuned text generators},
	url = {https://dl.acm.org/doi/10.1145/3571884.3604316},
	year = {2023},
}

@article{Cheng2023,
	abstract = {Deep learning techniques have advanced rapidly in recent years, leading to significant progress in pre-trained and fine-tuned large-scale AI models. For example, in the natural language processing domain, the traditional "pre-train, fine-tune"paradigm is shifting towards the "pre-train, prompt, and predict"paradigm, which has achieved great success on many tasks across different application domains such as ChatGPT/BARD for Conversational AI and P5 for a unified recommendation system. Moreover, there has been a growing interest in models that combine vision and language modalities (vision-language models) which are applied to tasks like Visual Captioning/Generation. Considering the recent technological revolution, it is essential to emphasize these paradigm shifts and highlight the paradigms with the potential to solve different tasks. We thus provide a platform for academic and industrial researchers to showcase their latest work, share research ideas, discuss various challenges, and identify areas where further research is needed in pre-training, fine-tuning, and prompt-learning methods for large-scale AI models. We foster the development of a strong research community focused on solving challenges related to large-scale AI models, providing superior and impactful strategies that can change people's lives in the future.},
	author = {Derek Cheng and Dhaval Patel and Linsey Pang and Sameep Mehta and Kexin Xie and Ed H. Chi and Wei Liu and Nitesh Chawla and James Bailey},
	doi = {10.1145/3580305.3599209},
	isbn = {9798400701030},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	keywords = {fine-tuning,large language models,large-scale ai models,pre-training,prompt-based learning},
	pages = {5853-5854},
	publisher = {Association for Computing Machinery},
	title = {{Foundations} and {Applications} in {Large}-scale {AI} {Models}: {Pre}-training, {Fine}-tuning, and {Prompt}-based {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3580305.3599209},
	year = {2023},
}

@article{Zhang2024,
	abstract = {Automated program repair (APR) aims to fix software bugs automatically without human debugging efforts and plays a crucial role in software development and maintenance. Despite the recent significant progress in the number of fixed bugs, APR is still challenged by a long-standing overfitting problem (i.e., the generated patch is plausible but overfitting). Various techniques have thus been proposed to address the overfitting problem. Recently, researchers have employed BERT to extract code features, which are then used to train a classifier for patch correctness prediction, indicating the potential of such pre-trained models in reasoning about patch correctness. However, BERT is restricted to feature extraction for classifier training without benefiting from the training process, potentially generating sub-optimal vector representations for patched code snippets. In this paper, we propose APPT, a pre-trained model-based automated patch correctness assessment technique by both pre-training and fine-tuning. APPT adopts a pre-trained model as the encoder stack, followed by an LSTM stack and a deep learning classifier. More importantly, the pre-trained model is fine-tuned in conjunction with other components as a whole pipeline to fully adapt it specifically for reasoning about patch correctness. Although our idea is general and can be built on various existing pre-trained models, we have implemented APPT based on the BERT model. We conduct an extensive experiment on 1,183 Defects4J patches and the experimental results show that APPT achieves prediction accuracy of 79.7% and recall of 83.2%, outperforming the state-of-the-art technique CACHE by 4.3% and 6.7%. Our additional investigation on 49,694 real-world patches shows that APPT achieves the optimum performance (exceeding 99% in five common metrics for assessing patch classification techniques) compared with existing representation learning techniques. We further investigate the impact of each component and find that they all positively contribute to APPT, e.g., the fine-tuning process and the LSTM stack increase F1-score by 10.22% and 4.11%, respectively. We also prove that adopting advanced pre-trained models can further provide substantial advancement (e.g., GraphCodeBERT-based APPT improves BERT-based APPT by 2.8% and 3.3% in precision and AUC, respectively), highlighting the generalizability of APPT. Overall, our study highlights the promising future of fine-tuning pre-trained models to assess patch correctness and reduce the manual inspection effort of debugging experts when deploying APR tools in practice.},
	author = {Quanjun Zhang and Chunrong Fang and Weisong Sun and Yan Liu and Tieke He and Xiaodong Hao and Zhenyu Chen},
	doi = {10.1109/TSE.2024.3354969},
	issn = {19393520},
	issue = {3},
	journal = {IEEE Transactions on Software Engineering},
	keywords = {Automated program repair,patch correctness,pre-trained model},
	pages = {474-494},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{APPT}: {Boosting} {Automated} {Patch} {Correctness} {Prediction} via {Fine}-{Tuning} {Pre}-{Trained} {Models}},
	volume = {50},
	year = {2024},
}

@article{Lee2024,
	abstract = {Advances in large language models (LLMs) have revolutionized the natural language processing field. However, the text generated by LLMs can result in various issues, such as fake news, misinformation, and social media spam. In addition, detecting machine-generated text is becoming increasingly difficult because it produces text that resembles human writing. We propose a new method for effectively detecting machine-generated text by applying adversarial training (AT) to pre-trained language models (PLMs), such as Bidirectional Encoder Representations from Transformers (BERT). We generated adversarial examples that appeared to have been modified by humans and applied them to the PLMs to improve the model's detection capabilities. The proposed method was validated on various datasets and experiments. It showed improved performance compared to traditional fine-tuning methods, with an average reduction in the probability of misclassification of machine-generated text by about 10%. We demonstrated the robustness of the model when generated with input tokens of different lengths and under different training data ratios. We suggested future research directions for applying AT to different languages and language model types. This study opens new possibilities for applying AT to the problem of machine-generated text detection and classification and contributes to building more effective detection models.},
	author = {Dong Hee Lee and Beakcheol Jang},
	doi = {10.1109/ACCESS.2024.3396820},
	issn = {21693536},
	journal = {IEEE Access},
	keywords = {Machine generated text detection,adversarial training,large language models,text classification},
	pages = {65333-65340},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Enhancing} {Machine}-{Generated} {Text} {Detection}: {Adversarial} {Fine}-{Tuning} of {Pre}-{Trained} {Language} {Models}},
	volume = {12},
	year = {2024},
}

@article{Su2021,
	abstract = {Fine-tuning pre-trained language models (PLMs) has demonstrated its effectiveness on various downstream NLP tasks recently. However, in many scenarios with limited supervised data, the conventional fine-tuning strategies cannot sufficiently capture the important semantic features for downstream tasks. To address this issue, we introduce a novel framework (named 'CSS-LM') to improve the fine-tuning phase of PLMs via contrastive semi-supervised learning. Specifically, given a specific task, we retrieve positive and negative instances from large-scale unlabeled corpora according to their domain-level and class-level semantic relatedness to the task. We then perform contrastive semi-supervised learning on both the retrieved unlabeled instances and original labeled instances to help PLMs capture crucial task-related semantic features. The experimental results show that CSS-LM achieves better results than the conventional fine-tuning strategy on a series of downstream tasks with few-shot settings by up to 7.8%, and outperforms the latest supervised contrastive fine-tuning strategy by up to 7.1%. Our datasets and source code will be available to provide more details.},
	author = {Yusheng Su and Xu Han and Yankai Lin and Zhengyan Zhang and Zhiyuan Liu and Peng Li and Jie Zhou and Maosong Sun},
	doi = {10.1109/TASLP.2021.3105013},
	issn = {23299304},
	journal = {IEEE/ACM Transactions on Audio Speech and Language Processing},
	keywords = {Contrastive learning,few-shot learning,fine-tuning,pre-trained language model,semi-supervised learning},
	pages = {2930-2941},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{CSS}-{LM}: {A} contrastive framework for semi-supervised fine-tuning of pre-trained language models},
	volume = {29},
	year = {2021},
}

@article{Liu2023,
	abstract = {Pre-trained code models (e.g. CodeBERT and CodeT5) have demonstrated their code intelligence in various software engineering tasks, such as code summarization. And full fine-tuning has become the typical approach to adapting these models to downstream tasks. However, full fine-tuning these large models can be computationally expensive and memory-intensive, particularly when training for multiple tasks. To alleviate this issue, several parameter-efficient fine-tuning methods (e.g. Adapter and LoRA) have been proposed to only train a small number of additional parameters, while keeping the original pre-trained parameters frozen. Although these methods claim superiority over the prior techniques, they seldom make a comprehensive and fair comparison on multiple software engineering tasks. Moreover, besides their potential in reducing fine-tuning costs and maintaining approximate performance, the effectiveness of these methods in low-resource, cross-language, and cross-project scenarios is inadequately studied. To this end, we first conduct experiments by fine-tuning state-of-the-art code models with these methods on both code understanding tasks and code generation tasks. The results show that, by tuning only 0.5% additional parameters, these methods may achieve comparable or higher performance than full fine-tuning in code understanding tasks, but they may exhibit slightly weaker performance in code generation tasks. We also investigate the impact of these methods with varying numbers of training samples and find that, a considerable number of samples (e.g. 1000 for clone detection) may be required for them to approximate the performance of full fine-tuning. Our experimental results in cross-language and cross-project scenarios demonstrate that by freezing most pre-trained parameters and tuning only 0.5% additional parameters, these methods achieve consistent improvements in models' transfer learning ability in comparison to full fine-tuning. Our code and data are available at https://github.com/anonymous-ase23/ CodeModelParameterEfficientFinetuning.},
	author = {Jiaxing Liu and Chaofeng Sha and Xin Peng},
	doi = {10.1109/ASE56229.2023.00125},
	isbn = {9798350329964},
	journal = {Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023},
	keywords = {fine-tuning,parameter-efficient,pre-trained code models,transfer learning},
	pages = {397-408},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{An} {Empirical} {Study} of {Parameter}-{Efficient} {Fine}-{Tuning} {Methods} for {Pre}-{Trained} {Code} {Models}},
	year = {2023},
}
@article{Zhang2021,
	abstract = {A Fine-tuning method has been mention in BERT, which is a pre-trained model use widely in NLP. In BERT and GPT, they hold that a standard fine-tuning model should there have a minimal difference between pre-trained architecture and the final downsteam architecture, and the task-special model will harm the result. In this paper, we mention two stream model which use hidden state pre-trained in BERT. In order to facilitate the validity of the verification method, We use sentiment analysis tasks to verify the results, which is a very simple text classification task in natural language process. Experiments on Yelp-review-poliarty show that using the same training data and other fine-tuning method, we can reduce ERROR by 0.21%. With the same setup, we can reduce ERROR of Amazon-review-poliarty by 0.13 %.},
	author = {Li Zhang and Yuxuan Hu},
	doi = {10.1109/ICPECA51329.2021.9362566},
	isbn = {9781728190037},
	journal = {Proceedings of 2021 IEEE International Conference on Power Electronics, Computer Applications, ICPECA 2021},
	keywords = {Fine-tuning,Pre-trained,Sentiment Analysis,Two Stream},
	pages = {905-908},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{A} fine-tuning approach research of pre-trained model with two stages},
	year = {2021},
}

% capitulo 2 - seccion 3

@article{Chu2020,
	abstract = {At the early phase of software development, functional requirements of the software often need to be represented in the developer's language, resulting in a so-called analysis model. Current works in literature aim to increase automation in software development by either generating automatically the analysis model from a use case specification or transforming the analysis model to a design model. However, up to now, to precisely specify use cases is still a challenge, preventing us from realizing this aim. This paper proposes a method to extract analysis classes from a use case specification. Within our method, use cases are represented using our domain-specific modeling language named USL. We then define algorithms with transformation rules as a representation of analysis patterns in order to extract analysis classes from the USL use case model. We develop a support tool for our method in which transformation rules are realized using the ATL model-to-model transformation technique.},
	author = {Minh Hue Chu and Duc Hanh Dang},
	doi = {10.1109/KSE50997.2020.9287702},
	isbn = {9781728145105},
	journal = {Proceedings - 2020 12th International Conference on Knowledge and Systems Engineering, KSE 2020},
	keywords = {Analysis Model,Model Transformation,UML/OCL,Use Case Specification},
	pages = {109-114},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Automatic} {Extraction} of {Analysis} {Class} {Diagrams} from {Use} {Cases}},
	year = {2020},
}
@article{Eiglsperger2003,
	abstract = {Class diagrams are among the most popular visualizations for object oriented software systems and have a broad range of applications. In many settings it is desirable that the placement of the diagram elements is determined automatically, especially when the diagrams are generated automatically which is usually the case in reverse engineering. For this reason the automatic layout of class diagram gained importance in the last years. Current approaches for the automatic layout of class diagrams are based on the hierarchic graph drawing paradigm. These algorithms produce good results for class diagrams with large and deep structural information, i.e., diagrams with a large and deep inheritance hierarchy. However, they do not perform satisfactorily in absence of this information. We propose in this work a new algorithm for automatic layout of class diagram which is based on the topology-shape-metrics approach. The algorithm is an adaption of sophisticated graph drawing algorithms which have proven their effectiveness in many applications. The algorithm works as well for class diagrams with rich structural information as for class diagrams with few or no structural information. It improves therefore the existing algorithms significantly. An implementation of the algorithm is used in the reverse engineering tool JarInspector.},
	author = {Markus Eiglsperger and Michael Kaufmann and Martin Siebenhaller},
	doi = {10.1145/774833.774860},
	isbn = {1581136420},
	journal = {Proceedings of ACM Symposium on Software Visualization},
	keywords = {Graph Theory-Graph Algorithms Keywords,Graph drawing,Miscellaneous G22 [Discrete Mathematics],UML Diagrams},
	pages = {189-198},
	publisher = {Association for Computing Machinery (ACM)},
	title = {{A} {Topology}-{Shape}-{Metrics} {Approach} for the {Automatic} {Layout} of {UML} {Class} {Diagrams}},
	url = {https://dl.acm.org/doi/10.1145/774833.774860},
	year = {2003},
}
@article{Milanova2005,
	abstract = {Knowing which associations are compositions is important in a tool for the reverse engineering of UML class diagrams. Firstly, recovery of composition relationships bridges the gap between design and code. Secondly, since composition relationships explicitly state a requirement that certain representations cannot be exposed, it is important to determine if this requirement is met by component code. Verifying that compositions are implemented properly may prevent serious program flaws due to representation exposure.We propose an implementation-level composition model based on ownership and a novel approach for identifying compositions in Java software. Our approach uses static ownership inference based on points-to analysis and is designed to work on incomplete programs. In our experiments, on average 40% of the examined fields account for relationships that are identified as compositions. We also present a precision evaluation which shows that for our code base our analysis achieves almost perfect precision - -that is, it almost never misses composition relationships. The results indicate that precise identification of interclass relationships can be done with a simple and inexpensive analysis, and thus can be easily incorporated in reverse engineering tools that support iterative model-driven development. Copyright 2005 ACM.},
	author = {Ana Milanova},
	doi = {10.1145/1101908.1101922},
	journal = {20th IEEE/ACM International Conference on Automated Software Engineering, ASE 2005},
	keywords = {Ownership,Points-to analysis,Reverse engineering,UML,ownership,points-to analysis,reverse engineering},
	pages = {76-85},
	title = {{Precise} identification of composition relationships for {UML} class diagrams},
	url = {https://dl.acm.org/doi/10.1145/1101908.1101922},
	year = {2005},
}
@article{Viesca2023,
	abstract = {The validation and verification of UML class diagrams are essential for ensuring the correctness of complex software systems. However, existing approaches have limitations, such as the inability to automatically deal with the frame problem. The frame problem occurs when operation specifications are incomplete, which can lead to unintended system behavior. This paper proposes an automated approach to specify frame conditions for class diagram verification. Frame conditions are operation contracts that explicitly define the effects an operation may have on the system to mitigate the frame problem. The proposed approach analyzes the behavioral specification of a class diagram to identify relevant information and specify frame conditions. To evaluate the approach, we used the approach to automatically specify frame conditions for different UML diagrams. We then simulated different execution scenarios and analyzed them to evaluate the effectiveness of the specified frame conditions in preventing unintended system behavior resulting from the frame problem. The approach has been implemented and put into practice in the Temporal Property Validator (TPV) tool.},
	author = {Antonio Rosales Viesca and Mustafa Al Lail},
	doi = {10.1109/MODELS-C59198.2023.00133},
	isbn = {9798350324983},
	journal = {Proceedings - 2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2023},
	keywords = {class diagram,frame problem,specification,verification},
	pages = {841-850},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Automated} {Mitigation} of {Frame} {Problem} in {UML} {Class} {Diagram} {Verification}},
	year = {2023},
}
@article{Gosala2021,
	abstract = {Unified Modeling Language (UML) includes various types of diagrams that help to study, analyze, document, design, or develop any software efficiently. Therefore, UML diagrams are of great advantage for researchers, software developers, and academicians. Class diagrams are the most widely used UML diagrams for this purpose. Despite its recognition as a standard modeling language for Object-Oriented software, it is difficult to learn. Although there exist repositories that aids the users with the collection of UML diagrams, there is still much more to explore and develop in this domain. The objective of our research was to develop a tool that can automatically classify the images as UML class diagrams and non-UML class diagrams. Earlier research used Machine Learning techniques for classifying class diagrams. Thus, they are required to identify image features and investigate the impact of these features on the UML class diagrams classification problem. We developed a new approach for automatically classifying class diagrams using the approach of Convolutional Neural Network under the domain of Deep Learning. We have applied the code on Convolutional Neural Networks with and without the Regularization technique. Our tool receives JPEG/PNG/GIF/TIFF images as input and predicts whether it is a UML class diagram image or not. There is no need to tag images of class diagrams as UML class diagrams in our dataset.},
	author = {Bethany Gosala and Sripriya Roy Chowdhuri and Jyoti Singh and Manjari Gupta and Alok Mishra},
	doi = {10.3390/APP11094267},
	issn = {2076-3417},
	issue = {9},
	journal = {Applied Sciences 2021, Vol. 11, Page 4267},
	keywords = {Convolutional Neural Networks (CNN),Deep Learning (DL),Machine Learning (ML),Object,Oriented modeling,Unified Modeling Language},
	pages = {4267},
	publisher = {Multidisciplinary Digital Publishing Institute},
	title = {{Automatic} {Classification} of {UML} {Class} {Diagrams} {Using} {Deep} {Learning} {Technique}: {Convolutional} {Neural} {Network}},
	volume = {11},
	url = {https://www.mdpi.com/2076-3417/11/9/4267/htm https://www.mdpi.com/2076-3417/11/9/4267},
	year = {2021},
}
@article{Wang2022,
	abstract = {Nowadays, the amount of data generated daily in various fields is constantly expanding, and the research field of UML diagram is no exception. It has strong expressiveness for complex systems, so it has become the best choice for modeling in many fields. Accordingly, this paper obtains and classifies UML diagram data based on convolution neural network diagram classification algorithm. This paper first analyzes the content and concept of UML, then further describes the importance of building a graphical UML classification model, the complete form convolutional neural network based on image is constructed by analyzing its theory, and then deduces the graphical UML classification model. Finally, a set of UML diagram data set is constructed by using the collected UML diagram design. After data preprocessing, the overall iteration times of the model and the accuracy and average time impact of UML diagram classification model and classification results are obtained. The graph classification algorithm model designed in this study has a good analysis and classification effect for UML object diagrams.Compared with the existing image-based convolutional neural networks and graph neural networks, the proposed UML diagram classification modeling method and GPC-GCN graph neural network have better performance for UML diagram classification. In this study, convolutional neural network technology is applied to the field of UML diagram classification model, thus promoting the development of related technologies in the field of UML diagram classification model.},
	author = {Fangli Wang},
	doi = {10.1016/J.IJLEO.2022.170463},
	issn = {0030-4026},
	journal = {Optik},
	pages = {170463},
	publisher = {Urban & Fischer},
	title = {{UML} diagram classification model based on convolution neural network},
	year = {2022},
}
@article{Koenig2023,
	abstract = {Design models are essential for many tasks in software engineering, such as consistency checking, code generation and design-to-code tracing. Unfortunately, many UML class diagrams are stored as images, which limits their use and evolution. It is therefore important to identify the semantic elements of design models from images. Although a number of studies focus on the recognition of a UML class diagram, very few address semantic analysis, which is a relatively complex task. In this paper, we propose a framework for training a learning model to categorise and locate semantic elements in class diagram from an image. A large set of annotated design models is proposed and made available online. Qualitative and quantitative evaluations have been carried out on two subsets of data, giving accuracy scores of 92.59% and 94.11% respectively. Evaluations highlight the ability of the proposed learning model to generalise to a wide range of examples.},
	author = {Aymeric Koenig and Benjamin Allaert and Emmanuel Renaux},
	doi = {10.1109/MODELS-C59198.2023.00099},
	isbn = {9798350324983},
	journal = {Proceedings - 2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion, MODELS-C 2023},
	keywords = {Computer vision,Deep learning,UML design,class diagram,object recognition},
	pages = {605-613},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{NEURAL}-{UML}: {Intelligent} {Recognition} {System} of {Structural} {Elements} in {UML} {Class} {Diagram}},
	year = {2023},
}
@article{Yang2022,
	abstract = {In model-driven engineering (MDE), UML class diagrams serve as a way to plan and communicate between developers. However, it is complex and resource-consuming. We propose an automated approach for the extraction of UML class diagrams from natural language software specifications. To develop our approach, we create a dataset of UML class diagrams and their English specifications with the help of volunteers. Our approach is a pipeline of steps consisting of the segmentation of the input into sentences, the classification of the sentences, the generation of UML class diagram fragments from sentences, and the composition of these fragments into one UML class diagram. We develop a quantitative testing framework specific to UML class diagram extraction. Our approach yields low precision and recall but serves as a benchmark for future research.},
	author = {Song Yang and Houari Sahraoui},
	doi = {10.1145/3550356.3561592},
	isbn = {9781450394673},
	journal = {Proceedings - ACM/IEEE 25th International Conference on Model Driven Engineering Languages and Systems, MODELS 2022: Companion Proceedings},
	keywords = {domain modeling,machine learning,model-driven engineering,natural language processing},
	pages = {396-403},
	publisher = {Association for Computing Machinery, Inc},
	title = {{Towards} automatically extracting {UML} class diagrams from natural language specifications},
	url = {https://dl.acm.org/doi/10.1145/3550356.3561592},
	year = {2022},
}
@article{Abdelnabi2021,
	abstract = {In the last years, many methods and tools for generating Unified Modeling Language (UML) class diagrams from natural language (NL) software requirements. These methods and tools deal with the transformation of NL textual requirements to UML diagrams. The transformation process involves analyzing NL requirements and extracting relevant information from the text to generate UML class models. This paper aims to survey the existing works of transforming textual requirements into UML class models to indicate their strengths and limitations. The paper provides a comprehensive explanation and evaluation of the existing approaches and tools. The automation degree, efficiency, and completeness, as well as the used techniques, are studied and analyzed. The study demonstrated the necessity of automating the process, in addition to combining artificial intelligence with engineering requirements and using Natural Language Processing (NLP) techniques to extract class diagrams from NL requirements.},
	author = {Esra A. Abdelnabi and Abdelsalam M. Maatuk and Mohammed Hagal},
	doi = {10.1109/MI-STA52233.2021.9464433},
	isbn = {9781665418560},
	journal = {2021 IEEE 1st International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering, MI-STA 2021 - Proceedings},
	keywords = {NLP,Requirement Engineering,System Development,UML class diagrams},
	pages = {288-293},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Generating} {UML} {Class} {Diagram} from {Natural} {Language} {Requirements}: {A} {Survey} of {Approaches} and {Techniques}},
	year = {2021},
}

% capitulo 2 - seccion 4

@article{Nasari2023,
	abstract = {Intelligence processing units (IPUs) are specifically designed accelerators that are dedicated to support artificial intelligence (AI) and machine learning (ML) workflows. Here, we report on the performance characteristics and code-porting experiences on Graphcore IPUs offered on the new National Science Foundation (NSF)-funded Accelerating Computing for Emerging Sciences (ACES) testbed. Our benchmarks compared performance of AI/ML frameworks on ACES IPUS to similar runs on the Graphcloud environment, a commercial IPU cloud service offered by Graphcore. We also ported two PyTorch neural network models from Graphics Processing Units (GPUs) to IPUs to ensure the efficacy of the software environment. The ported models include the TransCycleGAN model that is used in reconstructing high-resolution images from low-resolution images, and the Hierarchical Autoencoder that is for large-scale high-resolution scientific data compression in climate models. These models were successfully ported on mulitple IPUs using utilities in the Graphcore Poplar software development kit. Increasing the number of IPUs resulted in a considerable enhancement in the model's throughput.},
	author = {Abhinand Nasari and Lujun Zhai and Zhenhua He and Hieu Le and Jian Tao and Suxia Cui and Dhruva Chakravorty and Lisa M. Perez and Honggao Liu},
	doi = {10.1145/3569951.3603632},
	isbn = {9781450399852},
	journal = {PEARC 2023 - Computing for the common good: Practice and Experience in Advanced Research Computing},
	keywords = {Accelerating Computing for Emerging Sciences (ACES),Data Compression,Image Super-Resolution,Intelligence Processing Unit (IPU),ResNet50},
	pages = {231-236},
	publisher = {Association for Computing Machinery, Inc},
	title = {{Porting} {AI}/{ML} {Models} to {Intelligence} {Processing} {Units} ({IPUs})},
	url = {https://dl.acm.org/doi/10.1145/3569951.3603632},
	year = {2023},
}
@article{Heloise2021,
	abstract = {The interest in Artificial Intelligence (AI) based systems has been gaining momentum at a fast pace, both for software development teams and for society as a whole. This work aims to identify the guidelines and ethical principles for systems based on Artificial Intelligence. Design Science Research methodology was adopted in order to understand the various guidelines and principles existing in the literature. From the current landscape, a body of knowledge in the field of AI ethics is presented, with the purpose of supporting developers and Product Owners in identifying the guidelines and ethical principles in the literature so that they can be used during the software development process. Thus, this work will contribute to the various stakeholders in the development of ethical systems in the context of AI, such as: policy makers, ethicists, users, organizations, data scientists, development teams, among others.},
	author = {José Antonio Siqueira De Cerqueira and Heloise Acco Tives and Edna Dias Canedo},
	doi = {10.1145/3466933.3466969},
	isbn = {9781450384919},
	journal = {ACM International Conference Proceeding Series},
	keywords = {CCS CONCEPTS • Social and professional topics → Professional topics,Codes of ethics,Com-puting profession},
	publisher = {Association for Computing Machinery},
	title = {{Ethical} {Guidelines} and {Principles} in the {Context} of {Artificial} {Intelligence}},
	url = {https://dl.acm.org/doi/10.1145/3466933.3466969},
	year = {2021},
}
@article{XiaoTing2021,
	abstract = {This workshop will discuss the benefits and lessons learned in a project-oriented first course in software development. The intended audience for the workshop is similar to the makeup of the course...},
	author = {XiaoTing and AlbertMark V.},
	doi = {10.5555/3469581.3469593},
	journal = {Journal of Computing Sciences in Colleges},
	publisher = {Consortium for Computing Sciences in CollegesPUB305},
	title = {{On}-ramp to {AI}},
	url = {https://dl.acm.org/doi/10.5555/3469581.3469593},
	year = {2021},
}
@article{Cooper2024,
	abstract = {Artificial Intelligence (AI) is poised to revolutionize all aspects of business, particularly new-product development (NPD). Currently, our approach to NPD has remained largely unchanged for decades, yielding stubbornly poor results: only 30% of NP development projects become commercial successes. However, the AI revolution is set to alter this landscape significantly! Leading early adopter firms demonstrate that AI not only finds many applications in NPD but also offers substantial payoffs, such as 50% reductions in development times. This article provides an outline of the diverse and powerful applications of AI in NPD, offering numerous examples from leading companies. Examples include GE's use of digital models and twins to quickly test product designs in turbine development; BASFs use of AI to identify new molecules for use in customer formulations; and AI to generate new-product ideas, identify new-product opportunities, and even create new-product concepts. Our exploratory journey begins at the idea stage and traverses the entire new-product process to the postlaunch period. While AI might still resemble science fiction to many, that future is no longer fiction-it is here now. AI has arrived in full force! With an adoption window of about 13 years, the time is now to embrace AI in NPD in your business. AI will become a major milestone in NPD, perhaps the most important, within the decade.},
	author = {Robert G. Cooper},
	doi = {10.1109/EMR.2023.3336834},
	issn = {19374178},
	issue = {1},
	journal = {IEEE Engineering Management Review},
	keywords = {AI for new-product development (NPD),artificial intelligence (AI),generative AI,new-product development,new-product process,product innovation},
	pages = {195-211},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{The} {Artificial} {Intelligence} {Revolution} in {New}-{Product} {Development}},
	volume = {52},
	year = {2024},
}
@article{Lemon2009,
	abstract = {This paper augments Boehm-Turner's model of agile and plan-based software development augmented with an AI search algorithm. The AI search finds the key factors that predict for the success of agile or traditional plan-based software developments. According to our simulations and AI search algorithm: (1) in no case did agile methods perform worse than plan-based approaches; (2) in some cases, agile performed best. Hence, we recommend that the default development practice for organizations be an agile method. The simplicity of this style of analysis begs the question: why is so much time wasted on evidence-less debates on software process when a simple combination of simulation plus automatic search can mature the dialog much faster? © 2009 IEEE.},
	author = {Bryan Lemon and Aaron Riesbeck and Tim Menzies and Justin Price and Joseph D'Alessandro and Rikard Carlsson and Tomi Prifiti and Fayola Peters and Hiuhua Lu and Dan Port},
	doi = {10.1109/ASE.2009.42},
	isbn = {9780769538914},
	journal = {ASE2009 - 24th IEEE/ACM International Conference on Automated Software Engineering},
	pages = {580-584},
	title = {{Applications} of simulation and {AI} search: {Assessing} the relative merits of agile vs traditional software development},
	url = {https://dl.acm.org/doi/10.1109/ASE.2009.42},
	year = {2009},
}
@article{Rajbhoj2024,
	abstract = {The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.},
	author = {Asha Rajbhoj and Akanksha Somase and Piyush Kulkarni and Vinay Kulkarni},
	doi = {10.1145/3641399.3641403},
	isbn = {9798400717673},
	issue = {2024},
	journal = {ACM International Conference Proceeding Series},
	keywords = {AI in SDLC,Automated Software Development,ChatGPT,Generative AI,Large Language Models,SDLC automation},
	publisher = {Association for Computing Machinery},
	title = {{Accelerating} {Software} {Development} {Using} {Generative} {AI}: {ChatGPT} {Case} {Study}},
	volume = {11},
	url = {https://dl.acm.org/doi/10.1145/3641399.3641403},
	year = {2024},
}
@article{Petrovska2023,
	abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
	author = {Olga Petrovska and Lee Clift and Faron Moller},
	doi = {10.1145/3610969.3611132},
	isbn = {9781450385688},
	journal = {ACM International Conference Proceeding Series},
	keywords = {Apprenticeships,Education,Generative AI,Software Engineering},
	publisher = {Association for Computing Machinery},
	title = {{Generative} {AI} in {Software} {Development} {Education}: {Insights} from a {Degree} {Apprenticeship} {Programme}},
	url = {https://dl.acm.org/doi/10.1145/3610969.3611132},
	year = {2023},
}
@article{Ai2019,
	author = {Jun Ai and Wenzhu Su and Shaoxiong Zhang and Yiwen Yang},
	doi = {10.1109/TR.2019.2909786},
	issn = {0018-9529},
	issue = {3},
	journal = {IEEE Transactions on Reliability},
	pages = {844-858},
	publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
	title = {{A} {Software} {Network} {Model} for {Software} {Structure} and {Faults} {Distribution} {Analysis}},
	volume = {68},
	year = {2019},
}
@article{Sofian2022,
	abstract = {Artificial Intelligence (AI) has become a core feature of today's real-world applications, making it a trending topic within the software engineering (SE) community. The rise in the availability of AI techniques encompasses the capability to make rapid, automated, impactful decisions and predictions, leading to the adoption of AI techniques in SE. With industry revolution 4.0, the role of software engineering has become critical for developing productive, efficient, and quality software. Thus, there is a major need for AI techniques to be applied to enhance and improve the critical activities within the software engineering phases. Software is developed through intelligent software engineering phases. This paper concerns a systematic mapping study that aimed to characterize the publication landscape of AI techniques in software engineering. Gaps are identified and discussed by mapping these AI techniques against the SE phases to which they contributed. Many systematic mapping review papers have been produced only for a specific AI technique or a specific SE phase or activity. Hence, to our best of knowledge within the last decade, there is no systematic mapping review that has fully explored the overall trends in AI techniques and their application to all SE phases.},
	author = {Hazrina Sofian and Nur Arzilawati Md Yunus and Rodina Ahmad},
	doi = {10.1109/ACCESS.2022.3174115},
	issn = {21693536},
	journal = {IEEE Access},
	keywords = {Analysis and design,Artificial intelligence,Data mining,Deep learning,Machine learning,Requirements engineering,Software deployment,Software development,Software engineering,Software maintenance,Software testing},
	pages = {51021-51040},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Systematic} {Mapping}: {Artificial} {Intelligence} {Techniques} in {Software} {Engineering}},
	volume = {10},
	year = {2022},
}
@article{Tao2019,
	abstract = {With the fast growth of artificial intelligence and big data computing technologies, more and more software service systems have been developed using diverse machine learning models and technologies to make business and intelligent decisions based on their multimedia input to achieve intelligent features, such as image recognition, recommendation, decision making, prediction, etc. Nevertheless, there are increasing quality problems resulting in erroneous testing costs in enterprises and businesses. Existing work seldom discusses how to perform testing and quality validation for AI software. This paper focuses on quality validation for AI software function features. The paper provides our understanding of AI software testing for new features and requirements. In addition, current AI software testing categories are presented and different testing approaches are discussed. Moreover, test quality assessment and criteria analysis are illustrated. Furthermore, a practical study on quality validation for an image recognition system is performed through a metamorphic testing method. Study results show the feasibility and effectiveness of the approach.},
	author = {Chuanqi Tao and Jerry Gao and Tiexin Wang},
	doi = {10.1109/ACCESS.2019.2937107},
	issn = {21693536},
	journal = {IEEE Access},
	keywords = {AI software quality validation,AI testing,testing AI software},
	pages = {120164-120175},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Testing} and {Quality} {Validation} for {AI} {Software}-{Perspectives}, {Issues}, and {Practices}},
	volume = {7},
	year = {2019},
}

% referencias opciones

@article{Atkinson2023,
	abstract = {Generative artificial intelligence (GenAI) systems are disrupting how research is conducted across a wide range of disciplines. Many journals have decided not to allow these tools to be co-authors for the purposes of publication, but rather they must be acknowledged by authors as having been utilised in the writing process. Furthermore, due to the hallucinations that these models sometimes produce, authors are to review what is generated and recognise that they hold it to be true and accurate. To date, there has been varying research conducted on the accuracy of GenAI systems and their production of written text. However, new functions that allow GenAI systems to produce coding for constructing tools in computer programming languages highlights a new area that warrants investigation. Therefore, this article puts forth an account of using ChatGPT 3.5 to construct coding to be utilised for a Latent Dirichlet Allocation Topic Model (LDA-TM) for use in a Systematic Literature Review. This is hoped to address three elements of using ChatGPT 3.5 for coding: code review, error resolution, and scripting new code. The code will be aimed at designating an appropriate Hyper-parameter for the Random State for use in the LDA-TM. Within this context, this article will discuss the advantages and drawbacks of utilising this new tool and what it means for researchers who wish to augment their work with computer programming-based applications. To the authors knowledge, this is the first time this has been discussed within the context of the research being conducted.},
	author = {Cameron F. Atkinson},
	doi = {10.1007/S44163-023-00091-3/FIGURES/1},
	issn = {27310809},
	issue = {1},
	journal = {Discover Artificial Intelligence},
	keywords = {Artificial Intelligence,Computer Science,Engineering,general},
	pages = {1-18},
	publisher = {Springer Nature},
	title = {{ChatGPT} and computational-based research: benefits, drawbacks, and machine learning applications},
	volume = {3},
	url = {https://link.springer.com/article/10.1007/s44163-023-00091-3},
	year = {2023},
}
@article{Tang2023,
	abstract = {We present a detailed case study evaluating selective cognitive abilities (decision making and spatial reasoning) of two recently released generative transformer models, ChatGPT and DALL-E 2. Input prompts were constructed following neutral a priori guidelines, rather than adversarial intent. Post hoc qualitative analysis of the outputs shows that DALL-E 2 is able to generate at least one correct image for each spatial reasoning prompt, but most images generated are incorrect, even though the model seems to have a clear understanding of the objects mentioned in the prompt. Similarly, in evaluating ChatGPT on the rationality axioms developed under the classical Von Neumann-Morgenstern utility theorem, we find that, although it demonstrates some level of rational decision-making, many of its decisions violate at least one of the axioms even under reasonable constructions of preferences, bets, and decision-making prompts. ChatGPT’s outputs on such problems generally tended to be unpredictable: even as it made irrational decisions (or employed an incorrect reasoning process) for some simpler decision-making problems, it was able to draw correct conclusions for more complex bet structures. We briefly comment on the nuances and challenges involved in scaling up such a ‘cognitive’ evaluation or conducting it with a closed set of answer keys (‘ground truth’), given that these models are inherently generative and open-ended in responding to prompts.},
	author = {Zhisheng Tang and Mayank Kejriwal},
	doi = {10.1007/S44163-023-00067-3/METRICS},
	issn = {27310809},
	issue = {1},
	journal = {Discover Artificial Intelligence},
	keywords = {Artificial Intelligence,Computer Science,Engineering,general},
	pages = {1-19},
	publisher = {Springer Nature},
	title = {{Evaluating} deep generative models on cognitive tasks: a case study},
	volume = {3},
	url = {https://link.springer.com/article/10.1007/s44163-023-00067-3},
	year = {2023},
}
@article{Arcas2023,
	abstract = {Nowadays, Generative Large Language Models (GLLMs) have made a significant impact in the field of Artificial Intelligence (AI). One of the domains extensively explored for these models is their abi...},
	author = {Morales-GarcíaJuan and LlanesAntonio and Arcas-TúnezFrancisco and Terroso-SáenzFernando},
	doi = {10.1145/3663485},
	issn = {2157-6904},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	keywords = {ChatGPT,Copilot,Deep Learning,Generative Large Language Models (GLLMs),Time series forecasting},
	publisher = {ACMPUB27New York, NY},
	title = {{Developing} {Time} {Series} {Forecasting} {Models} with {Generative} {Large} {Language} {Models}},
	url = {https://dl.acm.org/doi/10.1145/3663485},
	year = {2023},
}
@article{Atouani2021,
	abstract = {Machine learning is a discipline which has become ubiquitous in the last few years. While the research of machine learning algorithms is very active and continues to reveal astonishing possibilities on a regular basis, the wide usage of these algorithms is shifting the research focus to the integration, maintenance, and evolution of AI-driven systems. Although there is a variety of machine learning frameworks on the market, there is little support for process automation and DevOps in machine learning-driven projects. In this paper, we discuss how metamodels can support the development of deep learning frameworks and help deal with the steadily increasing variety of learning algorithms. In particular, we present a deep learning-oriented artifact model which serves as a foundation for build automation and data management in iterative, machine learning-driven development processes. Furthermore, we show how schema and reference models can be used to structure and maintain a versatile deep learning framework. Feasibility is demonstrated on several state-of-the-art examples from the domains of image and natural language processing as well as decision making and autonomous driving.},
	author = {Abdallah Atouani and Jörg Christian Kirchhof and Evgeny Kusmenko and Bernhard Rumpe},
	doi = {10.1145/3486609.3487199},
	isbn = {9781450391122},
	journal = {GPCE 2021 - Proceedings of the 20th ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences, co-located with SPLASH 2021},
	keywords = {artifact models,artificial intelligence,build systems,compiler,machine learning,metamodeling,reference models,training},
	pages = {55-68},
	publisher = {Association for Computing Machinery, Inc},
	title = {{Artifact} and reference models for generative machine learning frameworks and build systems},
	url = {https://dl.acm.org/doi/10.1145/3486609.3487199},
	year = {2021},
}
@article{Godoy2023,
	abstract = {We evaluate AI-assisted generative capabilities on fundamental numerical kernels in high-performance computing (HPC), including AXPY, GEMV, GEMM, SpMV, Jacobi Stencil, and CG. We test the generated kernel codes for a variety of language-supported programming models, including (1) C++ (e.g., OpenMP [including offload], OpenACC, Kokkos, SyCL, CUDA, and HIP), (2) Fortran (e.g., OpenMP [including offload] and OpenACC), (3) Python (e.g., numpy, Numba, cuPy, and pyCUDA), and (4) Julia (e.g., Threads, CUDA.jl, AMDGPU.jl, and KernelAbstractions.jl). We use the GitHub Copilot capabilities powered by the GPT-based OpenAI Codex available in Visual Studio Code as of April 2023 to generate a vast amount of implementations given simple <kernel> + <programming model> + <optional hints> prompt variants. To quantify and compare the results, we propose a proficiency metric around the initial 10 suggestions given for each prompt. Results suggest that the OpenAI Codex outputs for C++ correlate with the adoption and maturity of programming models. For example, OpenMP and CUDA score really high, whereas HIP is still lacking. We found that prompts from either a targeted language such as Fortran or the more general-purpose Python can benefit from adding code keywords, while Julia prompts perform acceptably well for its mature programming models (e.g., Threads and CUDA.jl). We expect for these benchmarks to provide a point of reference for each programming model's community. Overall, understanding the convergence of large language models, AI, and HPC is crucial due to its rapidly evolving nature and how it is redefining human-computer interactions.},
	author = {William Godoy and Pedro Valero-Lara and Keita Teranishi and Prasanna Balaprakash and Jeffrey Vetter},
	doi = {10.1145/3605731.3605886},
	isbn = {9798400708435},
	journal = {ACM International Conference Proceeding Series},
	keywords = {GPT,GitHub Copilot,HPC,LLM,OpenAI Codex,generative AI,high-performance computing,large language models,numerical kernels,programming models},
	pages = {136-144},
	publisher = {Association for Computing Machinery},
	title = {{Evaluation} of {OpenAI} {Codex} for {HPC} {Parallel} {Programming} {Models} {Kernel} {Generation}},
	url = {https://dl.acm.org/doi/10.1145/3605731.3605886},
	year = {2023},
}
@article{Mubin2024,
	abstract = {This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.},
	author = {Omar Mubin and Fady Alnajjar and Zouheir Trabelsi and Luqman Ali and Medha Mohan Ambali Parambil and Zhao Zou},
	doi = {10.1109/ACCESS.2024.3356584},
	issn = {21693536},
	journal = {IEEE Access},
	keywords = {ChatGPT,NLM,artificial intelligence,natural language processing},
	pages = {30518-30532},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Tracking} {ChatGPT} {Research}: {Insights} {From} the {Literature} and the {Web}},
	volume = {12},
	year = {2024},
}
@article{Wu2023,
	abstract = {ChatGPT, an artificial intelligence generated content (AIGC) model developed by OpenAI, has attracted world-wide attention for its capability of dealing with challenging language understanding and generation tasks in the form of conversations. This paper briefly provides an overview on the history, status quo and potential future development of ChatGPT, helping to provide an entry point to think about ChatGPT. Specifically, from the limited open-accessed resources, we conclude the core techniques of ChatGPT, mainly including large-scale language models, in-context learning, reinforcement learning from human feedback and the key technical steps for developing Chat-GPT. We further analyze the pros and cons of ChatGPT and we rethink the duality of ChatGPT in various fields. Although it has been widely acknowledged that ChatGPT brings plenty of opportunities for various fields, mankind should still treat and use ChatGPT properly to avoid the potential threat, e.g., academic integrity and safety challenge. Finally, we discuss several open problems as the potential development of ChatGPT.},
	author = {Tianyu Wu and Shizhu He and Jingping Liu and Siqi Sun and Kang Liu and Qing Long Han and Yang Tang},
	doi = {10.1109/JAS.2023.123618},
	issn = {23299274},
	issue = {5},
	journal = {IEEE/CAA Journal of Automatica Sinica},
	keywords = {AIGC,ChatGPT,GPT-3,GPT-4,human feedback,large language models},
	pages = {1122-1136},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{A} {Brief} {Overview} of {ChatGPT}: {The} {History}, {Status} {Quo} and {Potential} {Future} {Development}},
	volume = {10},
	year = {2023},
}
@article{Valentina_gpt,
	abstract = {[First edition]. Generative AI models and AI language models are becoming increasingly popular due to their unparalleled capabilities. This book will provide you with insights into the inner workings of the LLMs and guide you through creating your own language models. You'll start with an introduction to the field of generative AI, helping you understand how these models are trained to generate new data. Next, you'll explore use cases where ChatGPT can boost productivity and enhance creativity. You'll learn how to get the best from your ChatGPT interactions by improving your prompt design and leveraging zero, one, and few-shots learning capabilities. The use cases are divided into clusters of marketers, researchers, and developers, which will help you apply what you learn in this book to your own challenges faster. You'll also discover enterprise-level scenarios that leverage OpenAI models' APIs available on Azure infrastructure; both generative models like GPT-3 and embedding models like Ada. For each scenario, you'll find an end-to-end implementation with Python, using Streamlit as the frontend and the LangChain SDK to facilitate models' integration into your applications. By the end of this book, you'll be well equipped to use the generative AI field and start using ChatGPT and OpenAI models' APIs in your own projects. Cover -- Title Page -- Copyright and credits -- Contributors -- Table of Contents -- Preface -- Part 1: Fundamentals of Generative AI and GPT Models -- Chapter 1: Introduction to Generative AI -- Introducing generative AI -- Domains of generative AI -- Text generation -- Image generation -- Music generation -- Video generation -- The history and current status of research -- Summary -- References -- Chapter 2: OpenAI and ChatGPT -- Beyond the Market Hype -- Technical requirements -- What is OpenAI? -- An overview of OpenAI model families -- Road to ChatGPT: the math of the model behind it -- The structure of RNNs -- The main limitations of RNNs -- Overcoming limitations -- introducing transformers -- GPT-3 -- ChatGPT: the state of the art -- Summary -- References -- Part 2: ChatGPT in Action -- Chapter 3: Getting Familiar with ChatGPT -- Setting up a ChatGPT account -- Familiarizing yourself with the UI -- Organizing chats -- Summary -- References -- Chapter 4: Understanding Prompt Design -- What is a prompt and why is it important? -- Zero-, one-, and few-shot learning -- typical of transformers models -- Principles of well-defined prompts to obtain relevant and consistent results -- Avoiding the risk of hidden bias and taking into account ethical considerations in ChatGPT -- Summary -- References -- Chapter 5: Boosting Day-to-Day Productivity with ChatGPT -- Technical requirements -- ChatGPT as a daily assistant -- Generating text -- Improving writing skills and translation -- Quick information retrieval and competitive intelligence -- Summary -- Chapter 6: Developing the Future with ChatGPT -- Why ChatGPT for developers? -- Generating, optimizing, and debugging code -- Generating documentation and code explainability -- Understanding ML model interpretability -- Translation among different programming languages -- Summary. Chapter 7: Mastering Marketing with ChatGPT -- Technical requirements -- Marketers' need for ChatGPT -- New product development and the go-to-market strategy -- A/B testing for marketing comparison -- Boosting Search Engine Optimization (SEO) -- Sentiment analysis to improve quality and increase customer satisfaction -- Summary -- Chapter 8: Research Reinvented with ChatGPT -- Researchers' need for ChatGPT -- Brainstorming literature for your study -- Providing support for the design and framework of your experiment -- Generating and formatting a bibliography -- Generating a presentation of the study -- Summary -- References -- Part 3: OpenAI for Enterprises -- Chapter 9: OpenAI and ChatGPT for Enterprises -- Introducing Azure OpenAI -- Technical requirements -- OpenAI and Microsoft for enterprise-level AI -- introducing Azure OpenAI -- Microsoft AI background -- Azure OpenAI Service -- Exploring Playground -- Why introduce a public cloud? -- Understanding responsible AI -- Microsoft's journey toward responsible AI -- Azure OpenAI and responsible AI -- Summary -- References -- Chapter 10: Trending Use Cases for Enterprises -- Technical requirements -- How Azure OpenAI is being used in enterprises -- Contract analyzer and generator -- Identifying key clauses -- Analyzing language -- Flagging potential issues -- Providing contract templates -- Frontend with Streamlit -- Understanding call center analytics -- Parameter extraction -- Sentiment analysis -- Classification of customers' requests -- Implementing the frontend with Streamlit -- Exploring semantic search -- Document embedding using LangChain modules -- Creating a frontend for Streamlit -- Summary -- References -- Chapter 11: Epilogue and Final Thoughts -- Recap of what we have learned so far -- This is just the beginning -- The advent of multimodal large language models. Microsoft Bing and the Copilot system -- The impact of generative technologies on industries -- a disruptive force -- Unveiling concerns about Generative AI -- Elon Musk calls for stopping development -- ChatGPT was banned in Italy by the Italian "Garante della Privacy" -- Ethical implications of Generative AI and why we need Responsible AI -- What to expect in the near future -- Summary -- References -- Index -- Other Books You May Enjoy.},
	author = {Valentina Alto},
	isbn = {9781805122838},
	pages = {286},
	title = {{Modern} generative {AI} with {ChatGPT} and {OpenAI} models : leverage the capabilities of {OpenAI}'s {LLM} for productivity and innovation with {GPT3} and {GPT4}},
}
@article{Yang2016,
	abstract = {Accidents caused by defective software systems have long been a nightmare. Though engineers utilize advanced techniques and rigorous quality control procedures, we still have to admit that the increasing complexity and expanding scale of software systems make it extremely difficult to guarantee high quality deliverables. Since large-scale software systems exhibit the characteristics of complex networks, applying the principles of complex networks to evaluate the quality of software systems has attracted attention from both academia and industry. Unfortunately, most current research studies focus only on one or a limited number of attributes of software structures which makes them ineffective in providing comprehensive and insightful quality evaluation for software structures. To overcome this problem, we propose an approach based on various software structural characteristics to evaluate software structures from modularity, hierarchy, complexity, and fault propagation points of view. A model based on these four aspects is proposed to better understand software structural quality. A prediction model is also proposed to provide insights on the nature of software evolution and its current status. Experiments using two software projects were performed against the thresholds obtained by evaluating more than 5,000 versions of open source projects. Our results suggest that the approach described in this paper can help us analyze real-world software projects for better quality evaluation.},
	author = {Yuwei Yang and Jun Ai and Xuelin Li and W. Eric Wong},
	doi = {10.1109/ISSRE.2016.46},
	isbn = {9781467390019},
	issn = {10719458},
	journal = {Proceedings - International Symposium on Software Reliability Engineering, ISSRE},
	keywords = {Software Complex Network,Software Structure Measurement,Structure Quality Evaluation},
	pages = {298-308},
	publisher = {IEEE Computer Society},
	title = {{MHCP} {Model} for {Quality} {Evaluation} for {Software} {Structure} {Based} on {Software} {Complex} {Network}},
	year = {2016},
}
@article{Chemnitz2023,
	abstract = {Automatic code generation has recently attracted large attention and is becoming more significant to the software development process. Solutions based on Machine Learning and Artificial Intelligence are being used to increase human and software efficiency in potent and innovative ways. In this paper, we aim to leverage these developments and introduce a novel approach to generating frontend component code for the popular Angular framework. We propose to do this using behavior-driven development test specifications as input to a transformer-based machine learning model; however, we do not provide any proof-of-concept solution in this work. Our approach aims to drastically reduce the development time needed for web applications while potentially increasing software quality and introducing new research ideas toward automatic code generation.},
	author = {Leon Chemnitz and David Reichenbach and Hani Aldebes and Mariam Naveed and Krishna Narasimhan and Mira Mezini},
	doi = {10.1109/CAIN58948.2023.00031},
	isbn = {9798350301137},
	journal = {Proceedings - 2023 IEEE/ACM 2nd International Conference on AI Engineering - Software Engineering for AI, CAIN 2023},
	keywords = {artificial intelligence,behavior driven development,code generation,frontend,machine learning,software engineering,software testing,transformer},
	pages = {139-144},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{Towards} {Code} {Generation} from {BDD} {Test} {Case} {Specifications}: {A} {Vision}},
	year = {2023},
}

@article{Scheschenja2024,
	abstract = {Purpose: This study explores the utility of the large language models, GPT-3 and GPT-4, for in-depth patient education prior to interventional radiology procedures. Further, differences in answer accuracy between the models were assessed. Materials and methods: A total of 133 questions related to three specific interventional radiology procedures (Port implantation, PTA and TACE) covering general information as well as preparation details, risks and complications and post procedural aftercare were compiled. Responses of GPT-3 and GPT-4 were assessed for their accuracy by two board-certified radiologists using a 5-point Likert scale. The performance difference between GPT-3 and GPT-4 was analyzed. Results: Both GPT-3 and GPT-4 responded with (5) “completely correct” (4) “very good” answers for the majority of questions ((5) 30.8% + (4) 48.1% for GPT-3 and (5) 35.3% + (4) 47.4% for GPT-4). GPT-3 and GPT-4 provided (3) “acceptable” responses 15.8% and 15.0% of the time, respectively. GPT-3 provided (2) “mostly incorrect” responses in 5.3% of instances, while GPT-4 had a lower rate of such occurrences, at just 2.3%. No response was identified as potentially harmful. GPT-4 was found to give significantly more accurate responses than GPT-3 (p = 0.043). Conclusion: GPT-3 and GPT-4 emerge as relatively safe and accurate tools for patient education in interventional radiology. GPT-4 showed a slightly better performance. The feasibility and accuracy of these models suggest their promising role in revolutionizing patient care. Still, users need to be aware of possible limitations. Graphical Abstract: (Figure presented.)},
	author = {Michael Scheschenja and Simon Viniol and Moritz B. Bastian and Joel Wessendorf and Alexander M. König and Andreas H. Mahnken},
	doi = {10.1007/S00270-023-03563-2/FIGURES/1},
	issn = {1432086X},
	issue = {2},
	journal = {CardioVascular and Interventional Radiology},
	keywords = {Artificial intelligence,Chat-GPT,Interventional radiology,Large language models,Patient education},
	pages = {245-250},
	pmid = {37872295},
	publisher = {Springer},
	title = {{Feasibility} of {GPT}-3 and {GPT}-4 for in-{Depth} {Patient} {Education} {Prior} to {Interventional} {Radiological} {Procedures}: {A} {Comparative} {Analysis}},
	volume = {47},
	url = {https://link.springer.com/article/10.1007/s00270-023-03563-2},
	year = {2024},
}

@article{Suarez2023,
	abstract = {Artificial intelligence has demonstrated its ability to solve lots of critical tasks, but at the cost of high computational requirements. Different hardware has been proposed to provide this computational power, each one with its benefits and drawbacks. However, the exploration of the different alternatives in an easy an integrated way is still a complex task. To solve so, this paper proposes a UML-based design flow where neural networks are initially specified and then automatically generated and trained using TensorFlow. The approach also enables automatic mapping of models to CPU, GPU and FPGAs, using Xilinx's Deep Learning Processor Units (DPUs). The framework also generates the communication codes required to connect the other system components with the implementation selected. This approach addresses design-space exploration challenges, system architecture definition, and improves implementation and training processes by saving time and effort.},
	author = {Daniel Suarez and Hector Posadas and Victor Fernandez},
	doi = {10.1109/DCIS58620.2023.10335992},
	isbn = {9798350303858},
	journal = {2023 38th Conference on Design of Circuits and Integrated Systems, DCIS 2023},
	keywords = {AI,CNN,FPGA,UML,automatic generation,design space exploration},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {{UML}-{Based} {Design} {Flow} for {Systems} with {Neural} {Networks}},
	year = {2023},
}

@article{Deinum2012,
	abstract = {Pro Spring MVC ofrece una cobertura en profundidad de Spring MVC y Spring Web Flow, dos frameworks web altamente personalizables y potentes que le ofrecen los desarrolladores y la comunidad de Spring Framework. Spring MVC es un moderno framework de aplicaciones web creado sobre Spring Framework, y Spring Web Flow es un proyecto que complementa a Spring MVC para crear módulos de controladores web reutilizables que encapsulan reglas de navegación de páginas enriquecidas. Junto con un análisis detallado del código y la funcionalidad, además de la primera cobertura publicada de Spring Web Flow 2.x, este libro incluye numerosos consejos y trucos para ayudarlo a aprovechar al máximo Spring MVC, Spring Web Flow y el desarrollo web en general. Spring MVC y Spring Web Flow se han actualizado en el nuevo Spring Framework 3.1 y están diseñados con consideraciones importantes para patrones de diseño y técnicas expertas de programación orientada a objetos. Este libro explica no solo las decisiones de diseño de los frameworks, sino también cómo puede aplicar diseños y técnicas similares a su propio código. Este libro tiene mucho cuidado en cubrir cada centímetro de Spring MVC y Spring Web Flow para brindarle una imagen completa. Junto con todas las características más conocidas de estos frameworks, descubrirá algunos nuevos tesoros ocultos. También aprenderá a ampliar los frameworks de forma correcta y segura para crear soluciones personalizadas. Este libro está dirigido a cualquier persona que desee escribir aplicaciones web robustas, modernas y útiles con Spring Framework. © 2012 por Marten Deinum y Koen Serneels con Colin Yates, Seth Ladd y Christophe Vanfleteren. Todos los derechos reservados.},
	author = {Marten Deinum and Koen Serneels},
	doi = {10.1007/978-1-4302-4156-0},
	isbn = {9781430241560},
	journal = {Volumen 9781430241560, Páginas 1 - 565},
	pages = {1-565},
	publisher = {Apress Media LLC},
	title = {{Pro} spring {MVC}: con flujo web},
	volume = {9781430241560},
	year = {2012},
}

%congreso
@inproceedings{schwarz2007modeling,
	title={{Modeling} with rendering primitives: an interactive non-photorealistic canvas},
	author={Schwarz, Martin and Isenberg, Tobias and Mason, Katherine and Carpendale, Sheelagh},
	booktitle={{Proceedings} of the 5th international symposium on {Non}-photorealistic animation and rendering},
	pages={15--22},
	year={2007}
}

%Tesis
@phdthesis{macindoe2013hybrid,
	title={{Hybrid} algorithms for efficient {Cholesky} decomposition and matrix inverse using multicore {CPUs} with {GPU} accelerators},
	author={Macindoe, GI},
	year={2013},
	school={UCL (University College London)}
}

%URL:
@misc{wikipediaComputerGraphics,
	author = {},
	title = {{C}omputer graphics - {W}ikipedia --- en.wikipedia.org},
	howpublished = {\url{https://en.wikipedia.org/wiki/Computer_graphics}},
	year = {},
	note = {[Accessed 07-06-2024]},
}

%https://www.getbibtex.com/
@misc{getbibtexBibTeXGenerator,
	author = {Karol Dzialowski},
	title = {{U}{R}{L} to {B}ib{T}e{X} generator - get {B}ib{T}e{X} for any website --- getbibtex.com},
	howpublished = {\url{https://www.getbibtex.com/}},
	year = {},
	note = {[Accessed 07-06-2024]},
}


