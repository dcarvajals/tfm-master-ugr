\label{chapter:estado-arte}\chapter[Estado del arte]{Estado del arte / Trabajos previos}

En este capítulo se presenta una revisión de los trabajos relacionados que constituyen el fundamento teórico y práctico de esta investigación. Se examinan los avances en modelos de lenguaje y NLP, el uso de técnicas de \textit{fine-tuning} para adaptar modelos pre-entrenados a tareas específicas, y las metodologías para la generación de diagramas UML a partir de texto natural. También se analizan las aplicaciones de IA en la ingeniería de software y se discuten las técnicas de evaluación y validación de modelos generativos. Esta revisión proporciona el contexto necesario para entender la relevancia y el impacto del uso de la IA en la generación automática de un diagrama de clases a partir de descripciones de casos de uso extendidos.

\section{Modelos de Lenguaje y LLM}

En esta sección se mencionarán algunos modelos de lenguaje entrenados previamente para comprender, generar y manipular el lenguaje humano. Los modelos desarrollados por OpenAI han revolucionado el campo del procesamiento del lenguaje natural, permitiendo entender y generar texto con gran precisión y coherencia. Los trabajos seleccionados mencionan múltiples aplicaciones y mejoras de estos modelos en diversas áreas. Desde la comparación entre respuestas humanas y generadas por IA, hasta la identificación de microservicios y la detección de información sensible en documentos textuales, los estudios destacan la versatilidad y el impacto transformador de estos avances tecnológicos.

\subsection{Modelos base de OpenAI}

OpenAI ofrece una gama de modelos avanzados diseñados para tareas específicas en el procesamiento del lenguaje natural (NLP). Estos modelos tienen capacidades únicas y se utilizan en diversas aplicaciones, desde la generación de texto hasta la identificación de patrones complejos en datos. A continuación, se describen algunos de los modelos base más destacados y se presentan casos de estudio que demuestran su uso y eficacia. 

\textit{\textbf{GPT-4}} es el modelo más reciente y avanzado de OpenAI, conocido por su capacidad mejorada para comprender y generar tanto texto como código. Es particularmente útil en aplicaciones que requieren alta precisión y comprensión contextual, como chatbots avanzados, asistentes virtuales y generación de contenido complejo. Una variante optimizada, GPT-4 Turbo, ofrece un rendimiento mejorado y es más rentable porque disminuye el consumo de recursos de los servidores que ejecutan el modelo y costos mas bajos por cada token procesado, ideal para aplicaciones que necesitan respuestas rápidas y eficientes sin sacrificar la calidad \cite{Elon2024}. Chen et al. \cite{Chen2023}, examinan el uso de GPT-4 para la creación de modelos de objetivos que permiten definir y representar visualmente los objetivos de los usuarios o del sistema en el contexto de la ingeniería de requisitos. A través de una serie de experimentos, se demuestra que GPT-4 retiene un conocimiento considerable sobre el modelado de objetivos, aunque con ciertas limitaciones en precisión y especificidad. La investigación resalta la necesidad de múltiples iteraciones y retroalimentación interactiva para mejorar la calidad de los modelos generados.

\textbf{\textit{GPT-3.5}} es una versión mejorada del popular modelo GPT-3, con capacidades avanzadas para entender y generar lenguaje natural y código. GPT-3.5 Turbo es el modelo más capaz y rentable dentro de esta categoría, optimizado para tareas de chat y generación de respuestas precisas y coherentes. También está disponible el modelo GPT-3.5 Turbo Instruct, utilizado principalmente para tareas de completado de texto, similar al modelo text-davinci-003, pero con mejoras en la precisión y capacidad de respuesta \cite{Elon2024}. Lucke y Frank  \cite{Lucke2024} examinan las diferencias y mejoras entre GPT-3.5 y GPT-4. Los autores destacan cómo GPT-3.5 es capaz de manejar tareas de generación de texto con alta coherencia y precisión, pero GPT-4 ofrece mejoras significativas en términos de comprensión contextual y generación de código. Este estudio proporciona una visión detallada de las capacidades y aplicaciones de ambos modelos en diversos contextos de NLP.

\textbf{\textit{GPT-3}} Este modelo fue entrenado con enormes cantidades de datos textuales para generar respuestas y realizar tareas complejas de NLP. GPT-3 puede llevar a cabo una amplia variedad de tareas, como la traducción de idiomas, la redacción de textos, el resumen de información, entre otros, gracias a su capacidad para entender y generar lenguaje humano de manera coherente \cite{Scheschenja2024}. Además, Scheschenja \cite{Scheschenja2024} indica que aunque es poderoso, tiene limitaciones, como la posibilidad de generar información incorrecta o "alucinaciones", cuando presenta respuestas que no están basadas en hechos reales. Sin embargo, sigue siendo un avance significativo en el campo de la inteligencia artificial, particularmente útil en áreas como la educación, el servicio al cliente, y el análisis de texto.

\textbf{\textit{Codex}} es un modelo derivado de GPT-3, diseñado específicamente para la generación de código y asistencia en tareas de programación. Puede interpretar y generar código en múltiples lenguajes de programación, lo que lo hace ideal para desarrollar aplicaciones, depurar código y automatizar tareas de programación. Codex es la base de herramientas como GitHub Copilot, que asisten a los desarrolladores sugiriendo líneas de código y completando funciones de manera autónoma \cite{Elon2024}. Ságodi et al. \cite{Sagodi2024}, exploran cómo GPT-4 y Codex pueden identificar y corregir vulnerabilidades en software real. Los resultados indican que Codex, al estar especializado en tareas de programación, muestra una alta precisión en la identificación y corrección de errores, mejorando significativamente la seguridad y eficiencia del desarrollo de software.

% CONTINUAR CON LA REVISION DESDE AQUI !

\subsection{Modelos para procesamiento de texto}

Gokcimen y Das \cite{Gokcimen2023} exploran la similitud entre respuestas generadas por humanos y las producidas por modelos de lenguaje, específicamente ChatGPT. Utilizan una serie de preguntas para comparar las respuestas de varios modelos basados en transformadores, incluyendo \textit{Robert a Base OpenAI Detector}, que mostró el mejor rendimiento en términos de generar respuestas similares a las humanas. Los autores destacan la capacidad de ChatGPT para producir respuestas coherentes y relevantes, acercándose mucho a la capacidad humana en la generación de lenguaje natural.

Este estudio no solo proporciona una comparación detallada entre los modelos, sino que también ofrece una perspectiva sobre cómo los avances en los modelos de lenguaje pueden ser aprovechados en aplicaciones prácticas. La investigación se basa en el uso del conjunto de datos HC3, diseñado para comparar las respuestas de ChatGPT con las de expertos humanos, abarcando una amplia gama de temas. Los resultados sugieren que, aunque existen diferencias entre las respuestas humanas y las generadas por IA, los modelos de lenguaje como ChatGPT están cada vez más cerca de replicar la complejidad y la sutileza de la comunicación humana. Esto subraya la importancia de seguir mejorando estos modelos para aplicaciones en diversas áreas, desde el servicio al cliente hasta la educación y la salud.

Muralitharan y Arumugam \cite{Muralitharan2024} presentan un algoritmo innovador que combina las capacidades del modelo BERT y LSTM para la detección de información sensible en documentos textuales. Este enfoque híbrido utiliza la robustez de BERT para el entendimiento contextual y la secuencialidad de LSTM para manejar largas secuencias de texto, logrando así una alta precisión en la identificación de datos sensibles. Los autores aplicaron su modelo en diversos conjuntos de datos, demostrando que su algoritmo supera a los métodos tradicionales en términos de precisión y capacidad de detección.

La investigación destaca cómo la combinación de diferentes arquitecturas de modelos de lenguaje puede mejorar significativamente las tareas de NLP, especialmente en contextos donde la privacidad y la seguridad de la información son críticas. Este trabajo no solo proporciona una herramienta efectiva para la detección de datos sensibles, sino que también abre nuevas vías para el desarrollo de algoritmos más sofisticados que puedan manejar tareas complejas en NLP con mayor eficiencia y precisión. La relevancia de este estudio se magnifica al considerar aplicaciones en industrias que manejan grandes volúmenes de datos personales y sensibles, como la salud y las finanzas, donde la precisión en la detección de información crítica es de suma importancia.

Xiubin Zhu et al. \cite{Zhu2023} presentan un método innovador para explicar modelos de caja negra mediante el uso de modelos de sustitutos locales basados en reglas difusas. Los modelos de sustitutos son aproximaciones más simples que imitan el comportamiento de modelos complejos, permitiendo su interpretación. Esta investigación tiene como objetivo proporcionar interpretaciones claras y comprensibles del comportamiento de modelos complejos, permitiendo a los usuarios entender mejor las razones detrás de ciertas decisiones. El enfoque desarrollado se aplica en varios escenarios, demostrando que los modelos de sustitutos pueden generar explicaciones precisas y útiles sin comprometer la precisión del modelo original.

Este estudio se enmarca dentro del creciente interés por la interpretabilidad en el aprendizaje automático, abordando uno de los mayores desafíos en el campo de la IA. Al ofrecer una metodología para generar explicaciones comprensibles, esta investigación no solo mejora la transparencia de los modelos de caja negra, sino que también facilita su adopción en sectores donde la interpretabilidad es crucial, como la medicina y las finanzas. Además, se relaciona con otros trabajos que buscan mejorar la precisión y comprensión de los modelos de lenguaje y NLP, destacando la importancia de desarrollar herramientas que permitan a los usuarios confiar y entender las decisiones automatizadas.

Hay una serie de trabajos \cite{Cámara2023}\cite{Bajaj2024}\cite{Arif2023}, que exploran diferentes aplicaciones de la IA generativa y herramientas de modelado en la ingeniería de software. El primer estudio \cite{Cámara2023} investiga el uso de ChatGPT en tareas de modelado de software, específicamente en la creación de diagramas UML. Los autores identifican limitaciones significativas en la capacidad de ChatGPT para generar modelos precisos y consistentes, destacando problemas de sintaxis, semántica y escalabilidad. A pesar de estas limitaciones, el estudio subraya el potencial de ChatGPT y la necesidad de desarrollar metodologías que aseguren la precisión y consistencia en modelos más grandes y complejos. 

Bajaj et al. \cite{Bajaj2024} propone un enfoque para la identificación de microservicios utilizando un modelo de transformador profundo de NLP en desarrollos greenfield. Los modelos transformadores usan un mecanismo de atención para procesar secuencias de datos de manera más eficiente. Este enfoque mejora la identificación y arquitectura de microservicios, facilitando el desarrollo de aplicaciones más robustas y escalables. Este estudio resalta el potencial de los modelos de transformadores en la ingeniería de software, particularmente en el diseño y desarrollo de microservicios, enfatizando la importancia de estas tecnologías para mejorar la eficiencia y precisión en el desarrollo de software.

Mohd et al. \cite{Arif2023} propone un método que combina UML y un marco \textit{non-functional requirements} (NFR) o en su traducción al español requisitos no funcionales para analizar los requisitos de un sistema de información. Este método sistemático utiliza diagramas UML para representar visualmente los elementos del sistema y sus interacciones, mejorando la claridad y precisión en la definición de requisitos. La investigación destaca la importancia de combinar enfoques basados en IA y metodologías tradicionales de ingeniería de software para ofrecer soluciones más robustas y efectivas. 

Al relacionar los estudios \cite{Cámara2023}\cite{Bajaj2024}\cite{Arif2023} , se evidencia una tendencia hacia el uso de herramientas de modelado avanzado para enfrentar los desafíos en la ingeniería de software, optimizando tanto la precisión como la eficiencia en el diseño de sistemas complejos. La combinación de IA generativa y técnicas de modelado tradicionales promete mejorar significativamente la calidad y escalabilidad del desarrollo de software, destacando la necesidad de una colaboración continua entre la comunidad de modelado de software y los desarrolladores de IA.

\section{Ajustes finos de modelos}   

El \textit{fine-tuning}, o ajuste fino, es una técnica esencial en el desarrollo y optimización de modelos de lenguaje pre-entrenados. Esta técnica permite adaptar los modelos a tareas específicas o mejorar su rendimiento general utilizando conjuntos de datos adicionales y específicos. Existen varios tipos de ajuste fino que se han desarrollado para maximizar la eficiencia y la efectividad de estos modelos en diversas aplicaciones. Entre los tipos más destacados se encuentran los siguientes: 

\begin{itemize}
	\item Específico para tareas
	\item General
	\item Específico para dominios
	\item Eficiente en parámetros
	\item Semi-supervisado
	\item Adversarial
	\item Enfocado en la seguridad
	\item Basado en instrucciones
	\item Dos etapas
\end{itemize}

Cada uno de estos enfoques tiene sus propias ventajas y se aplica en contextos diferentes para lograr resultados óptimos. A continuación, se analizan estudios que han implementado estos tipos de ajuste fino, destacando cómo cada uno ha contribuido a mejorar el rendimiento de los modelos de lenguaje en diversas tareas.

\subsection{Ajuste fino específico para tareas}

El ajuste fino específico para tareas se centra en adaptar modelos pre-entrenados para realizar de manera óptima tareas particulares. En el trabajo realizo por Ságodi et al. \cite{Sagodi2024}, los autores utilizan esta técnica para ajustar GPT-4 a la tarea de detección y corrección de vulnerabilidades en software real. El proceso de ajuste fino involucró el uso de un conjunto de datos extenso de código con vulnerabilidades etiquetadas. A través de iteraciones de entrenamiento, lograron que el modelo identificara y sugiriera correcciones precisas, mejorando la seguridad y eficiencia del software. Este enfoque específico permite que el modelo se enfoque en las particularidades de la tarea, mejorando significativamente su eficacia y reduciendo el tiempo necesario para la corrección de errores.

Un enfoque similar se observa en el trabajo de Zhang et al. \cite{Zhang2024} donde los autores aplican el ajuste fino para mejorar la predicción de la corrección de parches de software. Utilizando datos históricos de parches y sus resultados, adaptan el modelo pre-entrenado para predecir si un parche corregirá correctamente un error. Este ajuste fino específico para tareas permitió mejorar la precisión en la predicción, lo que es crucial para la estabilidad y seguridad del software. Los resultados demostraron una mejora significativa en la tasa de éxito de los parches aplicados, evidenciando la eficacia del ajuste fino en tareas críticas de mantenimiento de software.

Por su parte, Li et al. \cite{JunyiLi2024} han revisado diversas técnicas de ajuste fino aplicadas en la generación de texto. Destacan el uso del ajuste fino específico para tareas para mejorar la calidad de los textos generados en diferentes contextos, reafirmando la utilidad de este enfoque para optimizar el rendimiento en tareas específicas de generación de texto. Analizaron modelos ajustados para tareas como redacción creativa, generación de respuestas en chatbots, y creación de contenido técnico, mostrando mejoras sustanciales en la coherencia y relevancia de los textos generados.

\subsection{Ajuste fino general}

El ajuste fino general se enfoca en mejorar el rendimiento de los modelos pre-entrenados en una variedad de tareas. Lucke y Frank \cite{Lucke2024} comparan GPT-3.5 y GPT-4, destacando cómo ambos modelos han sido ajustados finamente para mejorar su capacidad de generación de texto y comprensión contextual. Este ajuste general permite que los modelos sean aplicables a múltiples tareas de NLP sin la necesidad de ajustes adicionales específicos para cada tarea. Los autores encontraron que el ajuste fino general mejoró significativamente la fluidez y coherencia de las respuestas generadas, haciéndolas más cercanas a la producción humana en una amplia gama de contextos.

Cheng et al. \cite{Cheng2023} mencionan diferentes dominios y aplicaciones del ajuste fino general. Los autores destacan cómo el ajuste fino general ha permitido a los modelos pre-entrenados alcanzar un rendimiento superior en una amplia gama de tareas, demostrando su versatilidad y eficiencia. Este enfoque se ha utilizado para mejorar modelos en aplicaciones como la traducción automática, la clasificación de textos y la generación de resúmenes, mostrando mejoras consistentes en precisión y relevancia.

\subsection{Ajuste fino específico para dominios}

El ajuste fino específico para dominios se aplica para adaptar los modelos a dominios específicos, mejorando su rendimiento en tareas relacionadas con dicho dominio. Chen et al. \cite{Chen2023} muestran que  se puede utilizar GPT-4 para la creación de modelos de objetivos en la ingeniería de requisitos. Al ajustar finamente GPT-4 con datos específicos del dominio de ingeniería de requisitos, el modelo logra comprender mejor las estructuras y terminologías específicas utilizadas, mejorando su rendimiento en esta tarea particular. El estudio muestra que el modelo podía generar modelos de objetivos con una precisión y coherencia mejoradas, facilitando el trabajo de los ingenieros de requisitos.

Cheng et al. \cite{Cheng2023} también abordan el ajuste fino específico para dominios, destacando cómo estas técnicas permiten a los modelos pre-entrenados adaptarse eficazmente a las necesidades de diferentes industrias y aplicaciones. Este enfoque facilita la integración de modelos de IA en contextos específicos, mejorando su relevancia y utilidad. Por ejemplo, se menciona la adaptación de modelos para el sector de la salud, donde se lograron mejoras en la precisión del diagnóstico y la generación de informes médicos mediante el ajuste fino con datos clínicos específicos.

\subsection{Ajuste fino eficiente en parámetros}

El ajuste fino eficiente en parámetros busca optimizar el proceso de ajuste fino minimizando los recursos necesarios mientras se mantiene o mejora el rendimiento del modelo. Liu et al. \cite{Liu2023} presentan métodos para ajustar finamente los modelos sin necesidad de ajustar todos los parámetros. Utilizan técnicas como la congelación de capas y la adaptación de solo ciertas partes del modelo, ahorrando recursos computacionales y tiempo. Este enfoque es especialmente útil en entornos con recursos limitados, permitiendo que los modelos logren un alto rendimiento sin incurrir en altos costos computacionales. Los resultados del estudio mostraron que los métodos eficientes en parámetros podían mantener un alto nivel de precisión y relevancia, demostrando la eficacia de estos enfoques en aplicaciones prácticas.

\subsection{Ajuste fino semi-supervisado}

El ajuste fino semi-supervisado combina datos etiquetados y no etiquetados para mejorar el rendimiento del modelo. Se ha propuesto una técnica \cite{Su2021} que aprovecha tanto datos supervisados como no supervisados para el ajuste fino. Este enfoque permite que el modelo aprenda de manera más eficiente, mejorando su capacidad de generalización y rendimiento en tareas de NLP. Los experimentos realizados demostraron que el uso de datos no etiquetados en combinación con datos etiquetados permitía al modelo mejorar su precisión en tareas como la clasificación de textos y la detección de entidades nombradas, destacando la utilidad del enfoque semi-supervisado. Los autores también resaltan cómo esta técnica puede reducir significativamente los costos y el tiempo asociados con la obtención de grandes cantidades de datos etiquetados, haciendo el ajuste fino más accesible y eficiente.

\subsection{Ajuste fino adversarial}

El ajuste fino adversarial mejora la robustez del modelo mediante la exposición a ejemplos adversariales durante el entrenamiento. Lee y Jang \cite{Lee2024} utilizan esta técnica para mejorar la detección de texto generado por máquinas. El modelo se ajusta finamente utilizando técnicas adversariales, lo que ayuda a que el modelo se vuelva más robusto ante intentos de generar texto que engañe a los sistemas de detección. Los autores encontraron que el modelo ajustado adversarialmente podía detectar con mayor precisión textos generados por IA, reduciendo las tasas de falsos positivos y negativos, lo cual es crucial para aplicaciones en seguridad y vigilancia digital. Este enfoque no solo mejora la precisión, sino que también incrementa la capacidad del modelo para adaptarse a nuevos tipos de ataques adversariales, haciendo que los sistemas de detección sean más resilientes frente a las evoluciones en las tácticas de generación de texto adversarial.

\subsection{Ajuste fino enfocado en la seguridad}

El ajuste fino enfocado en la seguridad se enfoca en adaptar el modelo para generar código seguro, minimizando vulnerabilidades y errores comunes. Li et al. \cite{JLi2024}  ajustan finamente un modelo de lenguaje grande para la generación segura de código, utilizando un conjunto de datos de código seguro. Este enfoque prioriza prácticas de codificación seguras, mejorando la seguridad del código generado. Los resultados mostraron que el modelo ajustado podía generar código que cumplía con altos estándares de seguridad, reduciendo significativamente las vulnerabilidades comunes en el desarrollo de software. Además, este enfoque ayuda a establecer mejores prácticas de codificación en los desarrolladores, ya que el modelo sugiere soluciones que siguen estándares de seguridad, promoviendo un entorno de desarrollo más seguro y robusto.

\subsection{Ajuste basado en instrucciones}

El ajuste basado en instrucciones \cite{Liesenfeld2023} ajusta el modelo para seguir instrucciones específicas de manera más efectiva. Este ajuste mejora la coherencia y precisión del modelo, al seguir instrucciones dadas por el usuario. El estudio mostró que el ajuste basado en instrucciones ayudó a reducir la ambigüedad y a mejorar la precisión de las respuestas generadas, haciendo que el modelo fuera más fiable y útil para tareas específicas. Además, este tipo de ajuste fino puede facilitar la personalización del modelo para distintos usuarios y aplicaciones, permitiendo que el modelo responda de manera más adecuada a las necesidades y expectativas particulares de los usuarios.

\subsection{Ajuste fino en dos etapas}

 Zhang y Hu \cite{Zhang2021} proponen esta técnica permite una mayor flexibilidad y eficiencia en el ajuste fino, utilizando tanto la estructura original del modelo como redes especializadas en tareas. Este enfoque mejora el rendimiento del modelo en tareas de clasificación de texto al combinar diferentes estrategias de ajuste. Los resultados mostraron que el ajuste fino en dos etapas permitía al modelo adaptarse mejor a las características específicas de las tareas, logrando una mayor precisión y eficiencia. Este método también facilita la incorporación de nuevas características o datos en el modelo sin necesidad de un reentrenamiento completo, optimizando el tiempo y los recursos necesarios para mantener y mejorar el rendimiento del modelo.

Como conclusión de esta sección podemos resaltar que estos estudios demuestran cómo diferentes tipos de ajuste fino pueden ser aplicados para optimizar modelos de lenguaje pre-entrenados en diversas tareas y dominios. Desde ajustes específicos para tareas particulares hasta enfoques generales y eficientes en parámetros, cada técnica de ajuste fino ofrece ventajas únicas que mejoran el rendimiento y la aplicabilidad de los modelos de lenguaje en múltiples contextos. Estas investigaciones no solo subrayan la importancia del ajuste fino en el desarrollo de modelos de lenguaje más precisos y eficientes, sino que también destacan las diversas estrategias que pueden ser empleadas para maximizar el potencial de estos modelos en aplicaciones prácticas. La implementación de estas técnicas de ajuste fino permite a los desarrolladores y científicos de datos adaptar modelos avanzados a necesidades específicas, mejorando la eficacia y relevancia de las soluciones basadas en inteligencia artificial en distintos sectores.

A continuación se explica cada símbolo utilizado en la tabla \ref{tab:ajuste-fino}:

\begin{itemize}
	\item Precisión: 
	\begin{itemize}
		\item El símbolo de estrella (\starL) indica el nivel de precisión de cada ajuste fino. Cinco estrellas (\starL\starL\starL\starL\starL) representan la máxima precisión.
	\end{itemize}
	\item Flexibilidad:
	\begin{itemize}
		\item La flecha hacia abajo ($\downarrow$) indica baja flexibilidad.
		\item La flecha hacia arriba ($\uparrow$) representa alta flexibilidad.
		\item La flecha de doble sentido ($\leftrightarrow$) indica flexibilidad media.
	\end{itemize}
	\item Velocidad:
	\begin{itemize}
		\item El reloj (\reloj) representa procesos lentos. Un reloj (\reloj) indica una velocidad lenta y dos relojes (\reloj\reloj) una velocidad media.
		\item El rayo (\rayo) simboliza velocidad rápida. Dos rayos (\rayo\rayo) indican una velocidad muy rápida.
	\end{itemize}
	\item Recursos:
	\begin{itemize}
		\item El símbolo de tuerca (\monitor) indica el uso de recursos computacionales. Más tuercas (\monitor\monitor\monitor\monitor) indican un mayor uso de recursos.
	\end{itemize}
\end{itemize}

\input{tablas/tabla-ajustes-finos.tex}

\section{Generación Automática de UML}

La generación automática de diagramas de clases UML ha avanzado significativamente gracias a la integración de técnicas de aprendizaje automático y NLP. Un enfoque innovador basado en métricas de forma-topología, que dividen el proceso en tres fases principales: planarización, ortogonalización y compactación, permite asegurar que los diagramas sean estéticamente agradables y legibles al minimizar cruces y optimizar la disposición de los elementos \cite{Eiglsperger2003}. Este método ha mejorado la disposición automática de diagramas, permitiendo manejar eficazmente tanto diagramas estructurados como aquellos con mínima estructura. Este método, implementado en herramientas como JarInspector, asegura una mejor estética y legibilidad, cruciales para la documentación y la ingeniería inversa del software. Además, se ha abordado el problema del marco en la verificación de diagramas UML mediante un enfoque automatizado que define propiedades invariantes, garantizando la integridad del sistema durante transiciones o cambios de estado. Esta integración de métodos formales y análisis estático es esencial para la fiabilidad y corrección de los diagramas de clases UML utilizados en el desarrollo de software.

% \cite{Viesca2023} buscar donde utilizarla

El uso de \textit{Convolutional Neural Networks} (CNNs) o en su traducción al español, Redes Neuronales Convolucionales pueden ser modeladas y especificadas utilizando UML como parte de un flujo de diseño automatizado. Este enfoque \cite{Suarez2023} permite la representación gráfica de la arquitectura de la red, incluyendo sus capas y conexiones, facilitando la implementación en plataformas como CPUs, GPUs y la eficiencia en tareas de aprendizaje profundo. Asimismo, la extracción automática de diagramas de clases propios del dominio del análisis a partir de descripciones de casos de uso mediante técnicas de NLP facilita la transición de los requisitos a los modelos del dominio del diseño, asegurando una representación precisa y completa de las funcionalidades del sistema \cite{Gosala2021}.

El sistema NEURAL-UML \cite{Chu2020}, diseñado para reconocer elementos estructurales en diagramas de clases UML mediante redes neuronales, mejora la automatización del análisis e interpretación de diagramas. Este sistema identifica clases, atributos, métodos y relaciones, aumentando la precisión y eficiencia en el reconocimiento de patrones estructurales complejos. La identificación precisa de relaciones de composición en diagramas UML es otro avance significativo, contribuyendo a la fiabilidad y precisión de los diagramas utilizados en el diseño detallado de software y arquitectura \cite{Koenig2023}.

La combinación de aprendizaje automático y técnicas basadas en patrones ha permitido desarrollar un enfoque totalmente automatizado para generar diagramas de clases UML a partir de especificaciones en lenguaje natural \cite{Milanova2005}. Este método, que incluye la creación de un conjunto de datos y el entrenamiento de un clasificador, reduce el esfuerzo manual y mejora la consistencia en la modelización del software. Además, un modelo de clasificación de diagramas UML basado en CNNs \cite{Yang2022} demuestra el potencial del aprendizaje profundo para automatizar y mejorar el procesamiento de artefactos de ingeniería de software, facilitando la gestión y análisis de diagramas en proyectos a gran escala.

En el ámbito educativo, se ha explorado la conversión de ejercicios textuales de ingeniería de software en diagramas de clases UML, utilizando técnicas de NLP y generación de diagramas \cite{Wang2022}. Este método automatiza la creación de materiales educativos y ejercicios, facilitando a los instructores la generación y validación de diagramas a partir de descripciones textuales. Por último, un \textit{survey} de enfoques y técnicas para generar diagramas de clases UML a partir de requisitos en lenguaje natural \cite{Abdelnabi2021} destaca los desafíos y avances en la automatización de este proceso. La revisión de métodos que van desde heurísticas hasta aprendizaje automático proporciona una visión integral del estado del arte y guía para futuros esfuerzos de investigación en este campo.

% \cite{Huber2022} buscar otra referencia

En conclusión, los avances en la generación automática de diagramas de clases UML, impulsados por técnicas de aprendizaje automático, NLP y métodos formales, han mejorado significativamente la precisión, eficiencia y utilidad práctica de estos diagramas en el desarrollo y diseño de software. Estos desarrollos no solo reducen el esfuerzo manual sino que también aseguran una representación más coherente y precisa de los sistemas, facilitando tanto la ingeniería de requisitos como el diseño detallado de software.

\section{IA en la ingeniería de software}

La integración de la IA en la ingeniería de software ha revolucionado múltiples aspectos del desarrollo y gestión del software. Desde la generación automática de código hasta la optimización de modelos y la validación de calidad, la IA ofrece soluciones avanzadas que mejoran la eficiencia, precisión y capacidad de respuesta en proyectos de software. Los artículos revisados en esta sección proporcionan un amplio panorama de cómo la IA está transformando la ingeniería de software en diversas áreas clave.

\subsection{Generación automática de código y prototipos}

Se ha explorado cómo ChatGPT puede acelerar el desarrollo de software mediante la generación automática de código y prototipos. En un caos de estudio, se asignaron tareas de programación a estudiantes de ingeniería de software \cite{Petrovska2023}, quienes utilizaron ChatGPT para resolver problemas previamente completados. Los resultados demostraron que ChatGPT puede reducir significativamente el tiempo de desarrollo, al proporcionar esqueletos de programas funcionales que requieren poca modificación, especialmente en lenguajes comunes, como Java. Sin embargo, los programadores experimentados que trabajaron con lenguajes menos comunes, como Dart, encontraron que el código generado por ChatGPT a menudo necesitaba ajustes significativos.

La utilidad de la IA generativa como herramienta de apoyo en el desarrollo de software se pone de manifiesto al aliviar la carga de trabajo de los desarrolladores y acelerar el proceso de codificación inicial. Además, se destaca la necesidad de equilibrar el uso de herramientas de IA para maximizar el aprendizaje y la comprensión de los estudiantes sin depender excesivamente de ellas. Los empleadores y estudiantes encuestados expresaron actitudes positivas hacia la integración de ChatGPT en el entorno educativo, siempre que se utilice como complemento y no como sustituto del aprendizaje profundo de los principios de programación \cite{Petrovska2023}.

\subsection{Simulación y búsqueda con IA}

Un estudio utiliza un modelo de simulación y un algoritmo de búsqueda AI para comparar los méritos relativos de los métodos de desarrollo de software ágiles y tradicionales \cite{Lemon2009}. Utilizando el modelo POM2, se llevaron a cabo numerosas simulaciones para identificar factores clave que influyen en el éxito de ambos enfoques. Los resultados indicaron que, en ningún caso, los métodos ágiles fueron inferiores a los tradicionales, y en muchos casos, los métodos ágiles superaron significativamente a los métodos planificados. Este hallazgo sugiere que las organizaciones deberían adoptar metodologías ágiles como práctica estándar para maximizar la eficiencia y adaptabilidad en proyectos de software.

La combinación de simulación y algoritmos de búsqueda IA puede proporcionar evidencia empírica sólida para respaldar decisiones estratégicas en la gestión de proyectos de software. La capacidad de modelar y simular diferentes políticas de priorización de requisitos y sus efectos en el desempeño del proyecto permite a los gerentes de proyectos tomar decisiones más informadas y basadas en datos. Este enfoque también pone de relieve la importancia de utilizar herramientas automatizadas para explorar y optimizar el espacio de diseño del proceso de desarrollo de software, asegurando que las mejores prácticas sean identificadas y adoptadas de manera sistemática \cite{Lemon2009}.

\subsection{Optimización y portabilidad de modelos de IA/ML}

Se abordan los desafíos y técnicas para portar modelos de inteligencia artificial y aprendizaje automático a unidades de procesamiento de inteligencia (IPUs). La optimización de modelos AI/ML para hardware especializado, como las IPUs, puede mejorar significativamente la eficiencia y velocidad de procesamiento. El trabajo presenta un análisis detallado de las adaptaciones necesarias para aprovechar al máximo las capacidades de las IPUs, que son cruciales para aplicaciones que requieren procesamiento intensivo de datos y en tiempo real \cite{Nasari2023}.

La importancia de ajustar y optimizar los modelos AI/ML para diferentes arquitecturas de hardware para maximizar el rendimiento y la eficiencia en diversas aplicaciones industriales y de investigación es esencial. Esto implica no solo la reimplementación de algoritmos en un nuevo entorno de hardware, sino también la reconsideración de los parámetros y configuraciones del modelo para alinearse con las capacidades específicas de las IPUs. Este enfoque es crucial para mantener la competitividad en un campo en rápida evolución como el de la inteligencia artificial y el aprendizaje automático \cite{Nasari2023}.

\subsection{Educación en Ingeniería de Software con IA Generativa}

Se presenta un estudio sobre la incorporación de ChatGPT en programas de aprendizaje de ingeniería de software. Se asignaron tareas a estudiantes de diferentes niveles de experiencia para utilizar ChatGPT en la resolución de problemas de programación. Los resultados mostraron que los programadores novatos encontraron muy útil la generación de código por parte de ChatGPT, ya que les proporcionaba soluciones rápidas y funcionales. Sin embargo, los programadores más experimentados, aunque reconocieron la utilidad de la herramienta, señalaron que el código generado a menudo requería modificaciones para cumplir con estándares de calidad y prácticas comunes en programación \cite{Petrovska2023}.

Las encuestas realizadas a los estudiantes y sus empleadores revelaron una actitud positiva hacia la integración de IA generativa en el currículo educativo, siempre que se utilice como una herramienta de apoyo y no como un sustituto del aprendizaje profundo de los principios de programación. Este estudio destaca la necesidad de una integración equilibrada de herramientas de IA en la educación, asegurando que los estudiantes desarrollen una comprensión sólida de los conceptos fundamentales mientras se benefician de las ventajas que ofrece la tecnología AI \cite{Petrovska2023}.

\subsection{Mapeo Sistemático de Técnicas de IA en Ingeniería de Software}

Un mapeo sistemático de las técnicas de inteligencia artificial aplicadas en la ingeniería de software identifica áreas clave de impacto y desarrollo. Se examina cómo la IA ha influido en la gestión de proyectos, la automatización de pruebas y la mejora de la calidad del software. El estudio proporciona una visión general comprensiva del estado del arte, destacando las tendencias actuales y los desafíos futuros en la implementación de tecnologías de IA en el ciclo de vida del software \cite{Sofian2022}.

El mapeo sistemático revela que la integración de la IA no solo mejora la eficiencia y precisión en el desarrollo de software, sino que también abre nuevas oportunidades para innovar y optimizar procesos tradicionales. Las técnicas de IA, como el aprendizaje automático y el procesamiento de lenguaje natural, están siendo cada vez más adoptadas para resolver problemas complejos en la ingeniería de software, proporcionando soluciones avanzadas y eficaces que transforman la manera en que se diseñan, desarrollan y mantienen los sistemas de software \cite{Sofian2022}.

\subsection{Pruebas de Calidad para Software con IA}

Se exploran los desafíos y prácticas en la validación y pruebas de software que incorpora componentes de IA. Las dificultades en asegurar la calidad y confiabilidad de software impulsado por IA se deben a la naturaleza dinámica e impredecible de los modelos de IA. Se proponen metodologías y prácticas para mejorar las pruebas y la validación, asegurando que los sistemas de software con IA sean robustos y confiables antes de su despliegue \cite{Tao2019}.

Este trabajo es esencial para desarrollar marcos de prueba que puedan manejar la complejidad y variabilidad inherentes a los sistemas de IA. Se abordan estrategias para identificar y mitigar riesgos potenciales, asegurando que los modelos de IA funcionen correctamente bajo diversas condiciones operativas. Este enfoque es crucial para garantizar que los sistemas de software con IA cumplan con los estándares de calidad necesarios para aplicaciones críticas, reduciendo el riesgo de fallos y aumentando la confianza en el uso de tecnologías de IA en entornos sensibles \cite{Tao2019}.

\subsection{Análisis de Estructura y Distribución de Fallos en Redes de Software}

Un modelo de red de software se presenta para analizar la estructura del software y la distribución de fallos. Utilizando técnicas de modelado de redes, se proporcionan insights sobre cómo se distribuyen los fallos dentro de la estructura del software, identificando patrones y áreas críticas que requieren atención. Este enfoque permite mejorar la calidad y mantenibilidad del software al facilitar una gestión más eficaz de los recursos de desarrollo y mantenimiento \cite{Ai2019}.

La investigación subraya la importancia de entender la topología del software para identificar y mitigar proactivamente las áreas propensas a fallos. Al analizar la red de software, se pueden detectar componentes vulnerables y optimizar el diseño para aumentar la robustez y confiabilidad del software. Este enfoque es esencial para desarrollar sistemas de software más resilientes y reducir el riesgo de fallos, mejorando así la calidad general y la eficiencia del desarrollo de software \cite{Ai2019}.

\subsection{Desarrollo de Nuevos Productos con IA}

La inteligencia artificial está transformando el desarrollo de nuevos productos, destacando su uso para acelerar el ciclo de desarrollo, mejorar la toma de decisiones y personalizar productos según las preferencias del cliente. La IA permite a las empresas responder más rápidamente a las demandas del mercado, innovar con mayor eficiencia y reducir los costos asociados con el desarrollo de productos \cite{Cooper2024}.

La capacidad de la IA para revolucionar el proceso de desarrollo de productos la convierte en un motor clave para la innovación y la competitividad en el mercado global. La implementación de técnicas de IA en el desarrollo de productos permite una mayor agilidad y adaptabilidad, lo que es crucial para mantener la relevancia en un entorno empresarial en rápida evolución. Este estudio subraya la importancia de integrar la IA en las estrategias de desarrollo de productos para aprovechar sus ventajas y mantenerse a la vanguardia en la industria \cite{Cooper2024}.
